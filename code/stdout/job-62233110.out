Job 62233110 released
Load modules

Lmod is automatically replacing "intel/2020.1.217" with "gcc/9.3.0".

Lmod Warning: Warning. On April 4th 2023, the default version of python will
become 3.10.
To keep using python 3.8, please load the python/3.8 module explicitly.

While processing the following module(s):
    Module fullname  Module Filename
    ---------------  ---------------
    python/3.8.10    /cvmfs/soft.computecanada.ca/easybuild/modules/2020/avx2/Core/python/3.8.10.lua


Due to MODULEPATH changes, the following have been reloaded:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

Create virtual environemnt
created virtual environment CPython3.8.10.final.0-64 in 5408ms
  creator CPython3Posix(dest=/localscratch/tbury.62233110.0/venv, clear=False, global=False)
  seeder FromAppData(download=False, pip=latest, setuptools=latest, wheel=latest, via=copy, app_data_dir=/home/tbury/.local/share/virtualenv/seed-app-data/v1.0.1)
  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator
Install packages
Ignoring pip: markers 'python_version < "3"' don't match your environment
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pip-23.0+computecanada-py3-none-any.whl
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 20.0.2
    Uninstalling pip-20.0.2:
      Successfully uninstalled pip-20.0.2
Successfully installed pip-23.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/tensorflow-2.11.0+computecanada-cp38-cp38-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/astunparse-1.6.3+computecanada-py2.py3-none-any.whl
Collecting termcolor>=1.1.0
  Using cached termcolor-2.2.0-py3-none-any.whl (6.6 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_pasta-0.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gast-0.4.0+computecanada-py3-none-any.whl
Requirement already satisfied: six>=1.12.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from tensorflow) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/absl_py-1.4.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/h5py-3.7.0+computecanada-cp38-cp38-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/keras-2.11.0+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/opt_einsum-3.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/libclang-14.0.1+computecanada-py2.py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/flatbuffers-20190709135844+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_estimator-2.11.0+computecanada-py2.py3-none-any.whl
Requirement already satisfied: typing-extensions>=3.6.6 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from tensorflow) (4.0.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/grpcio-1.51.3+computecanada-cp38-cp38-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wrapt-1.15.0+computecanada-cp38-cp38-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorflow_io_gcs_filesystem-0.26.0+computecanada-cp38-cp38-linux_x86_64.whl
Requirement already satisfied: setuptools in /localscratch/tbury.62233110.0/venv/lib/python3.8/site-packages (from tensorflow) (46.1.3)
Requirement already satisfied: numpy>=1.20 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from tensorflow) (1.22.2+computecanada)
Collecting protobuf<3.20,>=3.9.2
  Using cached protobuf-3.19.6-py2.py3-none-any.whl (162 kB)
Requirement already satisfied: packaging in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from tensorflow) (21.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard-2.11.2+computecanada-py3-none-any.whl
Requirement already satisfied: wheel<1.0,>=0.23.0 in /localscratch/tbury.62233110.0/venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)
Requirement already satisfied: requests<3,>=2.21.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Werkzeug-2.2.3+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_plugin_wit-1.8.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tensorboard_data_server-0.6.1+computecanada-py3-none-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/google_auth_oauthlib-0.4.6+computecanada-py2.py3-none-any.whl
Collecting google-auth<3,>=1.6.3
  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.2/177.2 kB 1.7 MB/s eta 0:00:00
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/Markdown-3.4.1+computecanada-py3-none-any.whl
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.7+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/rsa-4.9+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/cachetools-5.3.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1_modules-0.2.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests_oauthlib-1.3.1+computecanada-py2.py3-none-any.whl
Requirement already satisfied: importlib-metadata>=4.4 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.10.1+computecanada)
Requirement already satisfied: charset-normalizer~=2.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.11+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.8+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-2.1.2+computecanada-cp38-cp38-linux_x86_64.whl
Requirement already satisfied: zipp>=0.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.7.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyasn1-0.4.8+computecanada-py2.py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/oauthlib-3.2.2+computecanada-py3-none-any.whl
Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, MarkupSafe, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow
  Attempting uninstall: MarkupSafe
    Found existing installation: MarkupSafe 2.0.1+computecanada
    Not uninstalling markupsafe at /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages, outside environment /localscratch/tbury.62233110.0/venv
    Can't uninstall 'MarkupSafe'. No files were found to uninstall.
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
jupyter-server 2.3.0+computecanada requires nbconvert>=6.4.4, but you have nbconvert 6.4.2+computecanada which is incompatible.
jupyter-server 2.3.0+computecanada requires nbformat>=5.3.0, but you have nbformat 5.1.3+computecanada which is incompatible.
Successfully installed MarkupSafe-2.1.2+computecanada absl-py-1.4.0+computecanada astunparse-1.6.3+computecanada cachetools-5.3.0+computecanada flatbuffers-20190709135844+computecanada gast-0.4.0+computecanada google-auth-2.16.2 google-auth-oauthlib-0.4.6+computecanada google-pasta-0.2.0+computecanada grpcio-1.51.3+computecanada h5py-3.7.0+computecanada keras-2.11.0+computecanada libclang-14.0.1+computecanada markdown-3.4.1+computecanada oauthlib-3.2.2+computecanada opt-einsum-3.3.0+computecanada protobuf-3.19.6 pyasn1-0.4.8+computecanada pyasn1-modules-0.2.8+computecanada requests-oauthlib-1.3.1+computecanada rsa-4.9+computecanada tensorboard-2.11.2+computecanada tensorboard-data-server-0.6.1+computecanada tensorboard-plugin-wit-1.8.1+computecanada tensorflow-2.11.0+computecanada tensorflow-estimator-2.11.0+computecanada tensorflow-io-gcs-filesystem-0.26.0+computecanada termcolor-2.2.0 werkzeug-2.2.3+computecanada wrapt-1.15.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/scikit_learn-1.2.1+computecanada-cp38-cp38-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/threadpoolctl-3.1.0+computecanada-py3-none-any.whl
Requirement already satisfied: scipy>=1.3.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from scikit-learn) (1.8.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/numpy-1.24.2+computecanada-cp38-cp38-linux_x86_64.whl
Installing collected packages: threadpoolctl, numpy, joblib, scikit-learn
  Attempting uninstall: numpy
    Found existing installation: numpy 1.22.2+computecanada
    Not uninstalling numpy at /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages, outside environment /localscratch/tbury.62233110.0/venv
    Can't uninstall 'numpy'. No files were found to uninstall.
Successfully installed joblib-1.2.0+computecanada numpy-1.24.2+computecanada scikit-learn-1.2.1+computecanada threadpoolctl-3.1.0+computecanada
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting ewstools
  Using cached ewstools-2.1.0-py3-none-any.whl (27 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/statsmodels-0.13.5+computecanada-cp38-cp38-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/deprecation-2.1.0+computecanada-py2.py3-none-any.whl
Collecting lmfit>=0.9.0
  Using cached lmfit-1.1.0-py3-none-any.whl (90 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/arch-4.19+computecanada-cp38-cp38-linux_x86_64.whl
Requirement already satisfied: numpy>=1.14.0 in /localscratch/tbury.62233110.0/venv/lib/python3.8/site-packages (from ewstools) (1.24.2+computecanada)
Requirement already satisfied: scipy>=1.0.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from ewstools) (1.8.0+computecanada)
Requirement already satisfied: pandas>=0.23.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from ewstools) (1.4.0+computecanada)
Collecting plotly>=2.3.0
  Using cached plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)
Requirement already satisfied: cython>=0.29.14 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from arch>=4.4->ewstools) (0.29.27+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/property_cached-1.6.4+computecanada-py2.py3-none-any.whl
Requirement already satisfied: packaging in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from deprecation>=2.0->ewstools) (21.3+computecanada)
Collecting asteval>=0.9.28
  Using cached asteval-0.9.29-py3-none-any.whl (18 kB)
Collecting uncertainties>=3.1.4
  Using cached uncertainties-3.1.7-py2.py3-none-any.whl (98 kB)
Requirement already satisfied: python-dateutil>=2.8.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from pandas>=0.23.0->ewstools) (2.8.2+computecanada)
Requirement already satisfied: pytz>=2020.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from pandas>=0.23.0->ewstools) (2021.3+computecanada)
Collecting tenacity>=6.2.0
  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/patsy-0.5.3+computecanada-py2.py3-none-any.whl
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from packaging->deprecation>=2.0->ewstools) (3.0.7+computecanada)
Requirement already satisfied: six in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels>=0.9.0->ewstools) (1.16.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/future-0.18.2+computecanada-py3-none-any.whl
Installing collected packages: tenacity, property-cached, patsy, future, asteval, uncertainties, plotly, deprecation, statsmodels, lmfit, arch, ewstools
Successfully installed arch-4.19+computecanada asteval-0.9.29 deprecation-2.1.0+computecanada ewstools-2.1.0 future-0.18.2+computecanada lmfit-1.1.0 patsy-0.5.3+computecanada plotly-5.13.1 property-cached-1.6.4+computecanada statsmodels-0.13.5+computecanada tenacity-8.2.2 uncertainties-3.1.7
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Requirement already satisfied: matplotlib in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (3.5.1+computecanada)
Requirement already satisfied: fonttools>=4.22.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib) (4.29.1+computecanada)
Requirement already satisfied: cycler>=0.10 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib) (0.11.0+computecanada)
Requirement already satisfied: python-dateutil>=2.7 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from matplotlib) (2.8.2+computecanada)
Requirement already satisfied: pyparsing>=2.2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib) (3.0.7+computecanada)
Requirement already satisfied: pillow>=6.2.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib) (9.0.1+computecanada)
Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib) (21.3+computecanada)
Requirement already satisfied: kiwisolver>=1.0.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib) (1.3.2+computecanada)
Requirement already satisfied: numpy>=1.21 in /localscratch/tbury.62233110.0/venv/lib/python3.8/site-packages (from matplotlib) (1.24.2+computecanada)
Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0+computecanada)
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Collecting seaborn
  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)
Requirement already satisfied: numpy!=1.24.0,>=1.17 in /localscratch/tbury.62233110.0/venv/lib/python3.8/site-packages (from seaborn) (1.24.2+computecanada)
Requirement already satisfied: pandas>=0.25 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from seaborn) (1.4.0+computecanada)
Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from seaborn) (3.5.1+computecanada)
Requirement already satisfied: cycler>=0.10 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0+computecanada)
Requirement already satisfied: pyparsing>=2.2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.7+computecanada)
Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3+computecanada)
Requirement already satisfied: pillow>=6.2.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.0.1+computecanada)
Requirement already satisfied: kiwisolver>=1.0.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2+computecanada)
Requirement already satisfied: fonttools>=4.22.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.29.1+computecanada)
Requirement already satisfied: python-dateutil>=2.7 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2+computecanada)
Requirement already satisfied: pytz>=2020.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2022a/lib/python3.8/site-packages (from pandas>=0.25->seaborn) (2021.3+computecanada)
Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0+computecanada)
Installing collected packages: seaborn
Successfully installed seaborn-0.12.2
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/kaleido-0.2.1+computecanada-py2.py3-none-linux_x86_64.whl
Installing collected packages: kaleido
Successfully installed kaleido-0.2.1+computecanada
List all packages
Package                            Version
---------------------------------- ----------------------------
absl_py                            1.4.0+computecanada
anyio                              3.6.2+computecanada
arch                               4.19+computecanada
arff                               0.9+computecanada
argon2_cffi                        21.3.0+computecanada
argon2_cffi_bindings               21.2.0+computecanada
asteval                            0.9.29
asttokens                          2.2.1+computecanada
astunparse                         1.6.3+computecanada
async_generator                    1.10+computecanada
attrs                              21.4.0+computecanada
backcall                           0.2.0+computecanada
backports_abc                      0.5+computecanada
backports.shutil_get_terminal_size 1.0.0+computecanada
bcrypt                             3.2.0+computecanada
beautifulsoup4                     4.11.2+computecanada
bitstring                          3.1.9+computecanada
bleach                             4.1.0+computecanada
cachetools                         5.3.0+computecanada
certifi                            2021.10.8+computecanada
cffi                               1.15.0+computecanada
chardet                            4.0.0+computecanada
charset_normalizer                 2.0.11+computecanada
comm                               0.1.2+computecanada
contourpy                          1.0.7+computecanada
cryptography                       36.0.1+computecanada
cycler                             0.11.0+computecanada
Cython                             0.29.27+computecanada
deap                               1.0.1+computecanada
debugpy                            1.6.6+computecanada
decorator                          5.1.1+computecanada
defusedxml                         0.7.1+computecanada
deprecation                        2.1.0+computecanada
dnspython                          2.2.0+computecanada
ecdsa                              0.17.0+computecanada
entrypoints                        0.4+computecanada
ewstools                           2.1.0
executing                          1.2.0+computecanada
fastjsonschema                     2.16.2+computecanada
flatbuffers                        20190709135844+computecanada
fonttools                          4.29.1+computecanada
funcsigs                           1.0.2+computecanada
future                             0.18.2+computecanada
gast                               0.4.0+computecanada
google-auth                        2.16.2
google_auth_oauthlib               0.4.6+computecanada
google-pasta                       0.2.0+computecanada
grpcio                             1.51.3+computecanada
h5py                               3.7.0+computecanada
idna                               3.3+computecanada
importlib_metadata                 4.10.1+computecanada
importlib_resources                5.4.0+computecanada
ipykernel                          6.21.2+computecanada
ipython                            8.10.0+computecanada
ipython_genutils                   0.2.0+computecanada
ipywidgets                         7.6.5+computecanada
jedi                               0.18.2+computecanada
Jinja2                             3.0.3+computecanada
joblib                             1.2.0+computecanada
jsonschema                         4.4.0+computecanada
jupyter_client                     8.0.3+computecanada
jupyter_core                       5.2.0+computecanada
jupyter_events                     0.6.3+computecanada
jupyter_server                     2.3.0+computecanada
jupyter_server_terminals           0.4.4+computecanada
jupyterlab_pygments                0.1.2+computecanada
jupyterlab_widgets                 1.0.2+computecanada
kaleido                            0.2.1+computecanada
keras                              2.11.0+computecanada
kiwisolver                         1.3.2+computecanada
libclang                           14.0.1+computecanada
lmfit                              1.1.0
lockfile                           0.12.2+computecanada
Markdown                           3.4.1+computecanada
MarkupSafe                         2.1.2+computecanada
matplotlib                         3.5.1+computecanada
matplotlib_inline                  0.1.6+computecanada
mistune                            0.8.4+computecanada
mock                               4.0.3+computecanada
mpmath                             1.2.1+computecanada
nbclassic                          0.5.2+computecanada
nbclient                           0.5.10+computecanada
nbconvert                          6.4.2+computecanada
nbformat                           5.1.3+computecanada
nest_asyncio                       1.5.4+computecanada
netaddr                            0.8.0+computecanada
netifaces                          0.11.0+computecanada
nose                               1.3.7+computecanada
notebook                           6.4.8+computecanada
notebook_shim                      0.2.2+computecanada
numpy                              1.24.2+computecanada
oauthlib                           3.2.2+computecanada
opt-einsum                         3.3.0+computecanada
packaging                          21.3+computecanada
pandas                             1.4.0+computecanada
pandocfilters                      1.5.0+computecanada
paramiko                           2.9.2+computecanada
parso                              0.8.3+computecanada
path                               16.3.0+computecanada
path.py                            12.5.0+computecanada
pathlib2                           2.3.6+computecanada
patsy                              0.5.3+computecanada
paycheck                           1.0.2+computecanada
pbr                                5.8.1+computecanada
pexpect                            4.8.0+computecanada
pickleshare                        0.7.5+computecanada
Pillow                             9.0.1+computecanada
pip                                23.0+computecanada
pkgutil_resolve_name               1.3.10+computecanada
platformdirs                       2.5.2+computecanada
plotly                             5.13.1
prometheus_client                  0.13.1+computecanada
prompt_toolkit                     3.0.37+computecanada
property-cached                    1.6.4+computecanada
protobuf                           3.19.6
psutil                             5.9.4+computecanada
ptyprocess                         0.7.0+computecanada
pure_eval                          0.2.2+computecanada
pyarrow                            10.0.1
pyasn1                             0.4.8+computecanada
pyasn1-modules                     0.2.8+computecanada
pycparser                          2.21+computecanada
Pygments                           2.14.0+computecanada
PyNaCl                             1.5.0+computecanada
pyparsing                          3.0.7+computecanada
pyrsistent                         0.18.1+computecanada
python-dateutil                    2.8.2+computecanada
python_json_logger                 2.0.7+computecanada
pytz                               2021.3+computecanada
PyYAML                             6.0+computecanada
pyzmq                              25.0.0+computecanada
requests                           2.27.1+computecanada
requests_oauthlib                  1.3.1+computecanada
rfc3339_validator                  0.1.4+computecanada
rfc3986_validator                  0.1.1+computecanada
rsa                                4.9+computecanada
scikit_learn                       1.2.1+computecanada
scipy                              1.8.0+computecanada
seaborn                            0.12.2
Send2Trash                         1.8.0+computecanada
setuptools                         46.1.3
simplegeneric                      0.8.1+computecanada
singledispatch                     3.7.0+computecanada
six                                1.16.0+computecanada
sniffio                            1.3.0+computecanada
soupsieve                          2.4+computecanada
stack_data                         0.6.2+computecanada
statsmodels                        0.13.5+computecanada
sympy                              1.9+computecanada
tenacity                           8.2.2
tensorboard                        2.11.2+computecanada
tensorboard-data-server            0.6.1+computecanada
tensorboard_plugin_wit             1.8.1+computecanada
tensorflow                         2.11.0+computecanada
tensorflow_estimator               2.11.0+computecanada
tensorflow_io_gcs_filesystem       0.26.0+computecanada
termcolor                          2.2.0
terminado                          0.13.1+computecanada
testpath                           0.5.0+computecanada
threadpoolctl                      3.1.0+computecanada
tinycss2                           1.2.1+computecanada
tornado                            6.2+computecanada
traitlets                          5.9.0+computecanada
typing_extensions                  4.0.1+computecanada
uncertainties                      3.1.7
urllib3                            1.26.8+computecanada
wcwidth                            0.2.6+computecanada
webencodings                       0.5.1+computecanada
websocket_client                   1.5.1+computecanada
Werkzeug                           2.2.3+computecanada
wheel                              0.34.2
widgetsnbextension                 3.5.2+computecanada
wrapt                              1.15.0+computecanada
zipp                               3.7.0+computecanada
-----
 Running code repository with NSIMS=10000, NEPOCHS=200, MODEL_SIMS=2500, INC=5  
-----
-----
 Generate training data 
-----
Run forced PD simulations
Complete for tsid=1000
Complete for tsid=2000
Complete for tsid=3000
Complete for tsid=4000
Complete for tsid=5000
Complete for tsid=6000
Complete for tsid=7000
Complete for tsid=8000
Complete for tsid=9000
Complete for tsid=10000
Run null PD simulations
Complete for tsid=11000
Complete for tsid=12000
Complete for tsid=13000
Complete for tsid=14000
Complete for tsid=15000
Complete for tsid=16000
Complete for tsid=17000
Complete for tsid=18000
Complete for tsid=19000
Complete for tsid=20000
Run forced NS simulations
Complete for tsid=21000
Complete for tsid=22000
Complete for tsid=23000
Complete for tsid=24000
Complete for tsid=25000
Complete for tsid=26000
Complete for tsid=27000
Complete for tsid=28000
Complete for tsid=29000
Complete for tsid=30000
Run null NS simulations
Complete for tsid=31000
Complete for tsid=32000
Complete for tsid=33000
Complete for tsid=34000
Complete for tsid=35000
Complete for tsid=36000
Complete for tsid=37000
Complete for tsid=38000
Complete for tsid=39000
Complete for tsid=40000
Run forced fold simulations
Complete for tsid=41000
Complete for tsid=42000
Complete for tsid=43000
Complete for tsid=44000
Complete for tsid=45000
Complete for tsid=46000
Complete for tsid=47000
Complete for tsid=48000
Complete for tsid=49000
Complete for tsid=50000
Run null fold simulations
Complete for tsid=51000
Complete for tsid=52000
Complete for tsid=53000
Complete for tsid=54000
Complete for tsid=55000
Complete for tsid=56000
Complete for tsid=57000
Complete for tsid=58000
Complete for tsid=59000
Complete for tsid=60000
Run forced TC simulations
Complete for tsid=61000
Complete for tsid=62000
Complete for tsid=63000
Complete for tsid=64000
Complete for tsid=65000
Complete for tsid=66000
Complete for tsid=67000
Complete for tsid=68000
Complete for tsid=69000
Complete for tsid=70000
Run null TC simulations
Complete for tsid=71000
Complete for tsid=72000
Complete for tsid=73000
Complete for tsid=74000
Complete for tsid=75000
Complete for tsid=76000
Complete for tsid=77000
Complete for tsid=78000
Complete for tsid=79000
Complete for tsid=80000
Run forced PF simulations
Complete for tsid=81000
Complete for tsid=82000
Complete for tsid=83000
Complete for tsid=84000
Complete for tsid=85000
Complete for tsid=86000
Complete for tsid=87000
Complete for tsid=88000
Complete for tsid=89000
Complete for tsid=90000
Run null PF simulations
Complete for tsid=91000
Complete for tsid=92000
Complete for tsid=93000
Complete for tsid=94000
Complete for tsid=95000
Complete for tsid=96000
Complete for tsid=97000
Complete for tsid=98000
Complete for tsid=99000
Complete for tsid=100000
Script took 3919.1 seconds
-----
 Train classifier of type 1 
-----
2023-03-10 16:56:41.587002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 16:56:43.010895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 16:56:43.011972: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 16:56:43.012072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 16:57:38.607399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 16:57:39.222278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
Training DL with mtype=1 for 200 epochs with inter_train=True
Pad and normalise the data
Using 57000 training data samples
Using 1500 validation data samples
Train NN with seed=0 and model_type=1
Epoch 1/200
2023-03-10 16:57:47.135006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 16:57:47.618915: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:48.399413: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2af484019320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-03-10 16:57:48.399659: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla P100-PCIE-12GB, Compute Capability 6.0
2023-03-10 16:57:48.408161: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-10 16:57:48.527920: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:48.612152: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-03-10 16:57:48.720989: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.094214: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.094851: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.097442: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.154792: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.312291: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.395216: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 16:57:49.712899: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.

Epoch 1: val_accuracy improved from -inf to 0.51933, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 42s - loss: 1.5623 - accuracy: 0.3916 - val_loss: 1.3273 - val_accuracy: 0.5193 - 42s/epoch - 748ms/step
Epoch 2/200

Epoch 2: val_accuracy improved from 0.51933 to 0.56067, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 1.2584 - accuracy: 0.5329 - val_loss: 1.1652 - val_accuracy: 0.5607 - 32s/epoch - 566ms/step
Epoch 3/200

Epoch 3: val_accuracy improved from 0.56067 to 0.56200, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 1.1533 - accuracy: 0.5588 - val_loss: 1.1075 - val_accuracy: 0.5620 - 32s/epoch - 566ms/step
Epoch 4/200

Epoch 4: val_accuracy improved from 0.56200 to 0.57667, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 1.1070 - accuracy: 0.5647 - val_loss: 1.0701 - val_accuracy: 0.5767 - 32s/epoch - 568ms/step
Epoch 5/200

Epoch 5: val_accuracy improved from 0.57667 to 0.58000, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 1.0718 - accuracy: 0.5724 - val_loss: 1.0314 - val_accuracy: 0.5800 - 32s/epoch - 567ms/step
Epoch 6/200

Epoch 6: val_accuracy improved from 0.58000 to 0.58200, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 1.0443 - accuracy: 0.5794 - val_loss: 1.0127 - val_accuracy: 0.5820 - 32s/epoch - 564ms/step
Epoch 7/200

Epoch 7: val_accuracy improved from 0.58200 to 0.59400, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 1.0224 - accuracy: 0.5851 - val_loss: 0.9880 - val_accuracy: 0.5940 - 31s/epoch - 561ms/step
Epoch 8/200

Epoch 8: val_accuracy improved from 0.59400 to 0.60733, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 1.0018 - accuracy: 0.5942 - val_loss: 0.9697 - val_accuracy: 0.6073 - 32s/epoch - 567ms/step
Epoch 9/200

Epoch 9: val_accuracy did not improve from 0.60733
56/56 - 6s - loss: 0.9852 - accuracy: 0.5994 - val_loss: 0.9621 - val_accuracy: 0.5987 - 6s/epoch - 105ms/step
Epoch 10/200

Epoch 10: val_accuracy did not improve from 0.60733
56/56 - 6s - loss: 0.9736 - accuracy: 0.6003 - val_loss: 0.9530 - val_accuracy: 0.5980 - 6s/epoch - 105ms/step
Epoch 11/200

Epoch 11: val_accuracy improved from 0.60733 to 0.61800, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.9601 - accuracy: 0.6064 - val_loss: 0.9274 - val_accuracy: 0.6180 - 32s/epoch - 569ms/step
Epoch 12/200

Epoch 12: val_accuracy did not improve from 0.61800
56/56 - 6s - loss: 0.9493 - accuracy: 0.6084 - val_loss: 0.9340 - val_accuracy: 0.6127 - 6s/epoch - 105ms/step
Epoch 13/200

Epoch 13: val_accuracy improved from 0.61800 to 0.61867, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.9359 - accuracy: 0.6139 - val_loss: 0.9191 - val_accuracy: 0.6187 - 32s/epoch - 569ms/step
Epoch 14/200

Epoch 14: val_accuracy improved from 0.61867 to 0.62467, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.9256 - accuracy: 0.6165 - val_loss: 0.9016 - val_accuracy: 0.6247 - 32s/epoch - 571ms/step
Epoch 15/200

Epoch 15: val_accuracy improved from 0.62467 to 0.63200, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.9124 - accuracy: 0.6237 - val_loss: 0.8842 - val_accuracy: 0.6320 - 31s/epoch - 560ms/step
Epoch 16/200

Epoch 16: val_accuracy did not improve from 0.63200
56/56 - 6s - loss: 0.9017 - accuracy: 0.6267 - val_loss: 0.8916 - val_accuracy: 0.6260 - 6s/epoch - 105ms/step
Epoch 17/200

Epoch 17: val_accuracy did not improve from 0.63200
56/56 - 6s - loss: 0.8932 - accuracy: 0.6289 - val_loss: 0.8773 - val_accuracy: 0.6280 - 6s/epoch - 104ms/step
Epoch 18/200

Epoch 18: val_accuracy improved from 0.63200 to 0.63467, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.8839 - accuracy: 0.6294 - val_loss: 0.8614 - val_accuracy: 0.6347 - 32s/epoch - 569ms/step
Epoch 19/200

Epoch 19: val_accuracy improved from 0.63467 to 0.65333, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.8758 - accuracy: 0.6332 - val_loss: 0.8380 - val_accuracy: 0.6533 - 31s/epoch - 556ms/step
Epoch 20/200

Epoch 20: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8720 - accuracy: 0.6365 - val_loss: 0.8338 - val_accuracy: 0.6500 - 6s/epoch - 105ms/step
Epoch 21/200

Epoch 21: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8641 - accuracy: 0.6366 - val_loss: 0.8229 - val_accuracy: 0.6527 - 6s/epoch - 105ms/step
Epoch 22/200

Epoch 22: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8558 - accuracy: 0.6415 - val_loss: 0.8264 - val_accuracy: 0.6507 - 6s/epoch - 105ms/step
Epoch 23/200

Epoch 23: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8527 - accuracy: 0.6415 - val_loss: 0.8256 - val_accuracy: 0.6480 - 6s/epoch - 105ms/step
Epoch 24/200

Epoch 24: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8474 - accuracy: 0.6452 - val_loss: 0.8393 - val_accuracy: 0.6387 - 6s/epoch - 105ms/step
Epoch 25/200

Epoch 25: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8439 - accuracy: 0.6461 - val_loss: 0.8135 - val_accuracy: 0.6460 - 6s/epoch - 104ms/step
Epoch 26/200

Epoch 26: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8362 - accuracy: 0.6478 - val_loss: 0.8080 - val_accuracy: 0.6527 - 6s/epoch - 104ms/step
Epoch 27/200

Epoch 27: val_accuracy did not improve from 0.65333
56/56 - 6s - loss: 0.8326 - accuracy: 0.6485 - val_loss: 0.8192 - val_accuracy: 0.6507 - 6s/epoch - 105ms/step
Epoch 28/200

Epoch 28: val_accuracy improved from 0.65333 to 0.65533, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 33s - loss: 0.8296 - accuracy: 0.6488 - val_loss: 0.8096 - val_accuracy: 0.6553 - 33s/epoch - 587ms/step
Epoch 29/200

Epoch 29: val_accuracy did not improve from 0.65533
56/56 - 6s - loss: 0.8300 - accuracy: 0.6508 - val_loss: 0.8093 - val_accuracy: 0.6547 - 6s/epoch - 105ms/step
Epoch 30/200

Epoch 30: val_accuracy did not improve from 0.65533
56/56 - 6s - loss: 0.8238 - accuracy: 0.6526 - val_loss: 0.8065 - val_accuracy: 0.6547 - 6s/epoch - 104ms/step
Epoch 31/200

Epoch 31: val_accuracy improved from 0.65533 to 0.66133, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.8195 - accuracy: 0.6524 - val_loss: 0.7942 - val_accuracy: 0.6613 - 32s/epoch - 567ms/step
Epoch 32/200

Epoch 32: val_accuracy improved from 0.66133 to 0.66467, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.8185 - accuracy: 0.6539 - val_loss: 0.8135 - val_accuracy: 0.6647 - 31s/epoch - 562ms/step
Epoch 33/200

Epoch 33: val_accuracy did not improve from 0.66467
56/56 - 6s - loss: 0.8185 - accuracy: 0.6527 - val_loss: 0.8010 - val_accuracy: 0.6507 - 6s/epoch - 105ms/step
Epoch 34/200

Epoch 34: val_accuracy did not improve from 0.66467
56/56 - 6s - loss: 0.8109 - accuracy: 0.6567 - val_loss: 0.8141 - val_accuracy: 0.6520 - 6s/epoch - 104ms/step
Epoch 35/200

Epoch 35: val_accuracy did not improve from 0.66467
56/56 - 6s - loss: 0.8105 - accuracy: 0.6572 - val_loss: 0.8031 - val_accuracy: 0.6593 - 6s/epoch - 104ms/step
Epoch 36/200

Epoch 36: val_accuracy did not improve from 0.66467
56/56 - 6s - loss: 0.8097 - accuracy: 0.6562 - val_loss: 0.7812 - val_accuracy: 0.6613 - 6s/epoch - 104ms/step
Epoch 37/200

Epoch 37: val_accuracy improved from 0.66467 to 0.66533, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.8054 - accuracy: 0.6572 - val_loss: 0.7889 - val_accuracy: 0.6653 - 32s/epoch - 567ms/step
Epoch 38/200

Epoch 38: val_accuracy did not improve from 0.66533
56/56 - 6s - loss: 0.8042 - accuracy: 0.6586 - val_loss: 0.7875 - val_accuracy: 0.6573 - 6s/epoch - 105ms/step
Epoch 39/200

Epoch 39: val_accuracy did not improve from 0.66533
56/56 - 6s - loss: 0.8036 - accuracy: 0.6588 - val_loss: 0.7885 - val_accuracy: 0.6600 - 6s/epoch - 105ms/step
Epoch 40/200

Epoch 40: val_accuracy improved from 0.66533 to 0.66600, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.8011 - accuracy: 0.6597 - val_loss: 0.7889 - val_accuracy: 0.6660 - 31s/epoch - 561ms/step
Epoch 41/200

Epoch 41: val_accuracy did not improve from 0.66600
56/56 - 6s - loss: 0.8011 - accuracy: 0.6585 - val_loss: 0.7824 - val_accuracy: 0.6620 - 6s/epoch - 105ms/step
Epoch 42/200

Epoch 42: val_accuracy did not improve from 0.66600
56/56 - 6s - loss: 0.7980 - accuracy: 0.6614 - val_loss: 0.7958 - val_accuracy: 0.6547 - 6s/epoch - 105ms/step
Epoch 43/200

Epoch 43: val_accuracy did not improve from 0.66600
56/56 - 6s - loss: 0.7971 - accuracy: 0.6615 - val_loss: 0.7857 - val_accuracy: 0.6620 - 6s/epoch - 105ms/step
Epoch 44/200

Epoch 44: val_accuracy did not improve from 0.66600
56/56 - 6s - loss: 0.7938 - accuracy: 0.6630 - val_loss: 0.7836 - val_accuracy: 0.6607 - 6s/epoch - 105ms/step
Epoch 45/200

Epoch 45: val_accuracy improved from 0.66600 to 0.66933, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.7959 - accuracy: 0.6604 - val_loss: 0.7776 - val_accuracy: 0.6693 - 31s/epoch - 560ms/step
Epoch 46/200

Epoch 46: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7926 - accuracy: 0.6638 - val_loss: 0.7887 - val_accuracy: 0.6587 - 6s/epoch - 105ms/step
Epoch 47/200

Epoch 47: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7933 - accuracy: 0.6629 - val_loss: 0.7742 - val_accuracy: 0.6680 - 6s/epoch - 104ms/step
Epoch 48/200

Epoch 48: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7890 - accuracy: 0.6648 - val_loss: 0.7821 - val_accuracy: 0.6640 - 6s/epoch - 104ms/step
Epoch 49/200

Epoch 49: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7914 - accuracy: 0.6616 - val_loss: 0.7765 - val_accuracy: 0.6633 - 6s/epoch - 104ms/step
Epoch 50/200

Epoch 50: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7903 - accuracy: 0.6633 - val_loss: 0.7746 - val_accuracy: 0.6613 - 6s/epoch - 104ms/step
Epoch 51/200

Epoch 51: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7871 - accuracy: 0.6628 - val_loss: 0.7753 - val_accuracy: 0.6653 - 6s/epoch - 105ms/step
Epoch 52/200

Epoch 52: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7865 - accuracy: 0.6649 - val_loss: 0.7858 - val_accuracy: 0.6660 - 6s/epoch - 105ms/step
Epoch 53/200

Epoch 53: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7842 - accuracy: 0.6636 - val_loss: 0.7753 - val_accuracy: 0.6640 - 6s/epoch - 104ms/step
Epoch 54/200

Epoch 54: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7861 - accuracy: 0.6649 - val_loss: 0.7732 - val_accuracy: 0.6587 - 6s/epoch - 104ms/step
Epoch 55/200

Epoch 55: val_accuracy did not improve from 0.66933
56/56 - 6s - loss: 0.7840 - accuracy: 0.6641 - val_loss: 0.7724 - val_accuracy: 0.6620 - 6s/epoch - 105ms/step
Epoch 56/200

Epoch 56: val_accuracy improved from 0.66933 to 0.67267, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 34s - loss: 0.7827 - accuracy: 0.6646 - val_loss: 0.7721 - val_accuracy: 0.6727 - 34s/epoch - 605ms/step
Epoch 57/200

Epoch 57: val_accuracy did not improve from 0.67267
56/56 - 6s - loss: 0.7826 - accuracy: 0.6649 - val_loss: 0.7734 - val_accuracy: 0.6640 - 6s/epoch - 105ms/step
Epoch 58/200

Epoch 58: val_accuracy did not improve from 0.67267
56/56 - 6s - loss: 0.7792 - accuracy: 0.6679 - val_loss: 0.7749 - val_accuracy: 0.6667 - 6s/epoch - 104ms/step
Epoch 59/200

Epoch 59: val_accuracy did not improve from 0.67267
56/56 - 6s - loss: 0.7807 - accuracy: 0.6648 - val_loss: 0.7773 - val_accuracy: 0.6633 - 6s/epoch - 104ms/step
Epoch 60/200

Epoch 60: val_accuracy did not improve from 0.67267
56/56 - 6s - loss: 0.7794 - accuracy: 0.6663 - val_loss: 0.7685 - val_accuracy: 0.6667 - 6s/epoch - 104ms/step
Epoch 61/200

Epoch 61: val_accuracy did not improve from 0.67267
56/56 - 6s - loss: 0.7768 - accuracy: 0.6674 - val_loss: 0.7705 - val_accuracy: 0.6647 - 6s/epoch - 105ms/step
Epoch 62/200

Epoch 62: val_accuracy did not improve from 0.67267
56/56 - 6s - loss: 0.7780 - accuracy: 0.6676 - val_loss: 0.7720 - val_accuracy: 0.6687 - 6s/epoch - 105ms/step
Epoch 63/200

Epoch 63: val_accuracy improved from 0.67267 to 0.67333, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.7747 - accuracy: 0.6674 - val_loss: 0.7688 - val_accuracy: 0.6733 - 32s/epoch - 574ms/step
Epoch 64/200

Epoch 64: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7750 - accuracy: 0.6673 - val_loss: 0.7672 - val_accuracy: 0.6707 - 6s/epoch - 105ms/step
Epoch 65/200

Epoch 65: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7744 - accuracy: 0.6691 - val_loss: 0.7867 - val_accuracy: 0.6607 - 6s/epoch - 104ms/step
Epoch 66/200

Epoch 66: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7722 - accuracy: 0.6682 - val_loss: 0.7649 - val_accuracy: 0.6693 - 6s/epoch - 104ms/step
Epoch 67/200

Epoch 67: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7716 - accuracy: 0.6700 - val_loss: 0.7762 - val_accuracy: 0.6627 - 6s/epoch - 104ms/step
Epoch 68/200

Epoch 68: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7714 - accuracy: 0.6688 - val_loss: 0.7728 - val_accuracy: 0.6700 - 6s/epoch - 104ms/step
Epoch 69/200

Epoch 69: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7703 - accuracy: 0.6692 - val_loss: 0.7694 - val_accuracy: 0.6680 - 6s/epoch - 104ms/step
Epoch 70/200

Epoch 70: val_accuracy did not improve from 0.67333
56/56 - 6s - loss: 0.7709 - accuracy: 0.6694 - val_loss: 0.7641 - val_accuracy: 0.6720 - 6s/epoch - 104ms/step
Epoch 71/200

Epoch 71: val_accuracy improved from 0.67333 to 0.67400, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 33s - loss: 0.7718 - accuracy: 0.6703 - val_loss: 0.7680 - val_accuracy: 0.6740 - 33s/epoch - 580ms/step
Epoch 72/200

Epoch 72: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7691 - accuracy: 0.6697 - val_loss: 0.7598 - val_accuracy: 0.6707 - 6s/epoch - 105ms/step
Epoch 73/200

Epoch 73: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7666 - accuracy: 0.6701 - val_loss: 0.7679 - val_accuracy: 0.6713 - 6s/epoch - 104ms/step
Epoch 74/200

Epoch 74: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7682 - accuracy: 0.6723 - val_loss: 0.7578 - val_accuracy: 0.6653 - 6s/epoch - 104ms/step
Epoch 75/200

Epoch 75: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7675 - accuracy: 0.6698 - val_loss: 0.7728 - val_accuracy: 0.6687 - 6s/epoch - 105ms/step
Epoch 76/200

Epoch 76: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7669 - accuracy: 0.6706 - val_loss: 0.7696 - val_accuracy: 0.6667 - 6s/epoch - 105ms/step
Epoch 77/200

Epoch 77: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7648 - accuracy: 0.6734 - val_loss: 0.7636 - val_accuracy: 0.6693 - 6s/epoch - 105ms/step
Epoch 78/200

Epoch 78: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7643 - accuracy: 0.6737 - val_loss: 0.7593 - val_accuracy: 0.6727 - 6s/epoch - 105ms/step
Epoch 79/200

Epoch 79: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7636 - accuracy: 0.6731 - val_loss: 0.7676 - val_accuracy: 0.6653 - 6s/epoch - 105ms/step
Epoch 80/200

Epoch 80: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7644 - accuracy: 0.6701 - val_loss: 0.7588 - val_accuracy: 0.6740 - 6s/epoch - 105ms/step
Epoch 81/200

Epoch 81: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7629 - accuracy: 0.6725 - val_loss: 0.7544 - val_accuracy: 0.6700 - 6s/epoch - 105ms/step
Epoch 82/200

Epoch 82: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7635 - accuracy: 0.6720 - val_loss: 0.7523 - val_accuracy: 0.6687 - 6s/epoch - 104ms/step
Epoch 83/200

Epoch 83: val_accuracy did not improve from 0.67400
56/56 - 6s - loss: 0.7611 - accuracy: 0.6738 - val_loss: 0.7665 - val_accuracy: 0.6727 - 6s/epoch - 104ms/step
Epoch 84/200

Epoch 84: val_accuracy improved from 0.67400 to 0.67667, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 33s - loss: 0.7621 - accuracy: 0.6741 - val_loss: 0.7553 - val_accuracy: 0.6767 - 33s/epoch - 594ms/step
Epoch 85/200

Epoch 85: val_accuracy did not improve from 0.67667
56/56 - 6s - loss: 0.7595 - accuracy: 0.6748 - val_loss: 0.7607 - val_accuracy: 0.6700 - 6s/epoch - 105ms/step
Epoch 86/200

Epoch 86: val_accuracy improved from 0.67667 to 0.68133, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.7581 - accuracy: 0.6734 - val_loss: 0.7555 - val_accuracy: 0.6813 - 31s/epoch - 550ms/step
Epoch 87/200

Epoch 87: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7619 - accuracy: 0.6733 - val_loss: 0.7601 - val_accuracy: 0.6760 - 6s/epoch - 105ms/step
Epoch 88/200

Epoch 88: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7618 - accuracy: 0.6719 - val_loss: 0.7648 - val_accuracy: 0.6793 - 6s/epoch - 104ms/step
Epoch 89/200

Epoch 89: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7568 - accuracy: 0.6776 - val_loss: 0.7577 - val_accuracy: 0.6733 - 6s/epoch - 104ms/step
Epoch 90/200

Epoch 90: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7579 - accuracy: 0.6748 - val_loss: 0.7571 - val_accuracy: 0.6780 - 6s/epoch - 104ms/step
Epoch 91/200

Epoch 91: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7586 - accuracy: 0.6736 - val_loss: 0.7515 - val_accuracy: 0.6693 - 6s/epoch - 104ms/step
Epoch 92/200

Epoch 92: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7580 - accuracy: 0.6765 - val_loss: 0.7550 - val_accuracy: 0.6713 - 6s/epoch - 104ms/step
Epoch 93/200

Epoch 93: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7554 - accuracy: 0.6771 - val_loss: 0.7576 - val_accuracy: 0.6780 - 6s/epoch - 104ms/step
Epoch 94/200

Epoch 94: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7560 - accuracy: 0.6766 - val_loss: 0.7499 - val_accuracy: 0.6787 - 6s/epoch - 104ms/step
Epoch 95/200

Epoch 95: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7562 - accuracy: 0.6755 - val_loss: 0.7581 - val_accuracy: 0.6747 - 6s/epoch - 105ms/step
Epoch 96/200

Epoch 96: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7572 - accuracy: 0.6752 - val_loss: 0.7516 - val_accuracy: 0.6687 - 6s/epoch - 104ms/step
Epoch 97/200

Epoch 97: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7569 - accuracy: 0.6754 - val_loss: 0.7608 - val_accuracy: 0.6733 - 6s/epoch - 104ms/step
Epoch 98/200

Epoch 98: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7564 - accuracy: 0.6766 - val_loss: 0.7555 - val_accuracy: 0.6740 - 6s/epoch - 104ms/step
Epoch 99/200

Epoch 99: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7550 - accuracy: 0.6769 - val_loss: 0.7613 - val_accuracy: 0.6727 - 6s/epoch - 104ms/step
Epoch 100/200

Epoch 100: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7539 - accuracy: 0.6781 - val_loss: 0.7515 - val_accuracy: 0.6760 - 6s/epoch - 104ms/step
Epoch 101/200

Epoch 101: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7525 - accuracy: 0.6781 - val_loss: 0.7509 - val_accuracy: 0.6780 - 6s/epoch - 104ms/step
Epoch 102/200

Epoch 102: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7528 - accuracy: 0.6761 - val_loss: 0.7568 - val_accuracy: 0.6760 - 6s/epoch - 104ms/step
Epoch 103/200

Epoch 103: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7528 - accuracy: 0.6768 - val_loss: 0.7547 - val_accuracy: 0.6773 - 6s/epoch - 104ms/step
Epoch 104/200

Epoch 104: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7523 - accuracy: 0.6773 - val_loss: 0.7538 - val_accuracy: 0.6720 - 6s/epoch - 105ms/step
Epoch 105/200

Epoch 105: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7528 - accuracy: 0.6773 - val_loss: 0.7605 - val_accuracy: 0.6753 - 6s/epoch - 105ms/step
Epoch 106/200

Epoch 106: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7535 - accuracy: 0.6772 - val_loss: 0.7546 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 107/200

Epoch 107: val_accuracy did not improve from 0.68133
56/56 - 6s - loss: 0.7515 - accuracy: 0.6766 - val_loss: 0.7614 - val_accuracy: 0.6753 - 6s/epoch - 105ms/step
Epoch 108/200

Epoch 108: val_accuracy improved from 0.68133 to 0.68333, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 33s - loss: 0.7494 - accuracy: 0.6772 - val_loss: 0.7540 - val_accuracy: 0.6833 - 33s/epoch - 592ms/step
Epoch 109/200

Epoch 109: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7489 - accuracy: 0.6785 - val_loss: 0.7523 - val_accuracy: 0.6787 - 6s/epoch - 105ms/step
Epoch 110/200

Epoch 110: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7489 - accuracy: 0.6796 - val_loss: 0.7557 - val_accuracy: 0.6793 - 6s/epoch - 105ms/step
Epoch 111/200

Epoch 111: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7498 - accuracy: 0.6779 - val_loss: 0.7500 - val_accuracy: 0.6773 - 6s/epoch - 105ms/step
Epoch 112/200

Epoch 112: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7486 - accuracy: 0.6799 - val_loss: 0.7512 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 113/200

Epoch 113: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7483 - accuracy: 0.6786 - val_loss: 0.7507 - val_accuracy: 0.6807 - 6s/epoch - 105ms/step
Epoch 114/200

Epoch 114: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7492 - accuracy: 0.6764 - val_loss: 0.7604 - val_accuracy: 0.6773 - 6s/epoch - 105ms/step
Epoch 115/200

Epoch 115: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7477 - accuracy: 0.6786 - val_loss: 0.7501 - val_accuracy: 0.6827 - 6s/epoch - 105ms/step
Epoch 116/200

Epoch 116: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7491 - accuracy: 0.6785 - val_loss: 0.7489 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 117/200

Epoch 117: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7468 - accuracy: 0.6786 - val_loss: 0.7506 - val_accuracy: 0.6773 - 6s/epoch - 105ms/step
Epoch 118/200

Epoch 118: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7490 - accuracy: 0.6784 - val_loss: 0.7542 - val_accuracy: 0.6833 - 6s/epoch - 105ms/step
Epoch 119/200

Epoch 119: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7475 - accuracy: 0.6796 - val_loss: 0.7524 - val_accuracy: 0.6753 - 6s/epoch - 105ms/step
Epoch 120/200

Epoch 120: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7467 - accuracy: 0.6786 - val_loss: 0.7522 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 121/200

Epoch 121: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7447 - accuracy: 0.6800 - val_loss: 0.7507 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 122/200

Epoch 122: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7448 - accuracy: 0.6810 - val_loss: 0.7542 - val_accuracy: 0.6773 - 6s/epoch - 105ms/step
Epoch 123/200

Epoch 123: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7456 - accuracy: 0.6789 - val_loss: 0.7440 - val_accuracy: 0.6813 - 6s/epoch - 104ms/step
Epoch 124/200

Epoch 124: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7463 - accuracy: 0.6793 - val_loss: 0.7568 - val_accuracy: 0.6780 - 6s/epoch - 104ms/step
Epoch 125/200

Epoch 125: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7444 - accuracy: 0.6812 - val_loss: 0.7494 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 126/200

Epoch 126: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7453 - accuracy: 0.6807 - val_loss: 0.7488 - val_accuracy: 0.6787 - 6s/epoch - 104ms/step
Epoch 127/200

Epoch 127: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7451 - accuracy: 0.6786 - val_loss: 0.7442 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 128/200

Epoch 128: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7441 - accuracy: 0.6808 - val_loss: 0.7550 - val_accuracy: 0.6747 - 6s/epoch - 105ms/step
Epoch 129/200

Epoch 129: val_accuracy did not improve from 0.68333
56/56 - 6s - loss: 0.7431 - accuracy: 0.6790 - val_loss: 0.7599 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 130/200

Epoch 130: val_accuracy improved from 0.68333 to 0.68400, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 33s - loss: 0.7429 - accuracy: 0.6805 - val_loss: 0.7479 - val_accuracy: 0.6840 - 33s/epoch - 588ms/step
Epoch 131/200

Epoch 131: val_accuracy did not improve from 0.68400
56/56 - 6s - loss: 0.7460 - accuracy: 0.6786 - val_loss: 0.7466 - val_accuracy: 0.6807 - 6s/epoch - 106ms/step
Epoch 132/200

Epoch 132: val_accuracy did not improve from 0.68400
56/56 - 6s - loss: 0.7428 - accuracy: 0.6796 - val_loss: 0.7501 - val_accuracy: 0.6787 - 6s/epoch - 105ms/step
Epoch 133/200

Epoch 133: val_accuracy did not improve from 0.68400
56/56 - 6s - loss: 0.7439 - accuracy: 0.6796 - val_loss: 0.7600 - val_accuracy: 0.6740 - 6s/epoch - 105ms/step
Epoch 134/200

Epoch 134: val_accuracy did not improve from 0.68400
56/56 - 6s - loss: 0.7415 - accuracy: 0.6816 - val_loss: 0.7481 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 135/200

Epoch 135: val_accuracy did not improve from 0.68400
56/56 - 6s - loss: 0.7429 - accuracy: 0.6818 - val_loss: 0.7458 - val_accuracy: 0.6773 - 6s/epoch - 104ms/step
Epoch 136/200

Epoch 136: val_accuracy did not improve from 0.68400
56/56 - 6s - loss: 0.7403 - accuracy: 0.6829 - val_loss: 0.7484 - val_accuracy: 0.6780 - 6s/epoch - 105ms/step
Epoch 137/200

Epoch 137: val_accuracy improved from 0.68400 to 0.68600, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.7406 - accuracy: 0.6804 - val_loss: 0.7451 - val_accuracy: 0.6860 - 32s/epoch - 569ms/step
Epoch 138/200

Epoch 138: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7379 - accuracy: 0.6826 - val_loss: 0.7499 - val_accuracy: 0.6740 - 6s/epoch - 105ms/step
Epoch 139/200

Epoch 139: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7416 - accuracy: 0.6834 - val_loss: 0.7475 - val_accuracy: 0.6833 - 6s/epoch - 104ms/step
Epoch 140/200

Epoch 140: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7402 - accuracy: 0.6815 - val_loss: 0.7501 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 141/200

Epoch 141: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7402 - accuracy: 0.6821 - val_loss: 0.7527 - val_accuracy: 0.6840 - 6s/epoch - 104ms/step
Epoch 142/200

Epoch 142: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7399 - accuracy: 0.6818 - val_loss: 0.7427 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 143/200

Epoch 143: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7384 - accuracy: 0.6825 - val_loss: 0.7525 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 144/200

Epoch 144: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7374 - accuracy: 0.6834 - val_loss: 0.7516 - val_accuracy: 0.6793 - 6s/epoch - 104ms/step
Epoch 145/200

Epoch 145: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7389 - accuracy: 0.6831 - val_loss: 0.7590 - val_accuracy: 0.6787 - 6s/epoch - 104ms/step
Epoch 146/200

Epoch 146: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7391 - accuracy: 0.6833 - val_loss: 0.7471 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 147/200

Epoch 147: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7358 - accuracy: 0.6844 - val_loss: 0.7479 - val_accuracy: 0.6807 - 6s/epoch - 104ms/step
Epoch 148/200

Epoch 148: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7369 - accuracy: 0.6832 - val_loss: 0.7465 - val_accuracy: 0.6793 - 6s/epoch - 104ms/step
Epoch 149/200

Epoch 149: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7359 - accuracy: 0.6837 - val_loss: 0.7523 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 150/200

Epoch 150: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7376 - accuracy: 0.6827 - val_loss: 0.7505 - val_accuracy: 0.6773 - 6s/epoch - 105ms/step
Epoch 151/200

Epoch 151: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7392 - accuracy: 0.6821 - val_loss: 0.7482 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 152/200

Epoch 152: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7362 - accuracy: 0.6845 - val_loss: 0.7449 - val_accuracy: 0.6807 - 6s/epoch - 105ms/step
Epoch 153/200

Epoch 153: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7370 - accuracy: 0.6827 - val_loss: 0.7545 - val_accuracy: 0.6820 - 6s/epoch - 104ms/step
Epoch 154/200

Epoch 154: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7358 - accuracy: 0.6842 - val_loss: 0.7438 - val_accuracy: 0.6780 - 6s/epoch - 104ms/step
Epoch 155/200

Epoch 155: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7357 - accuracy: 0.6841 - val_loss: 0.7481 - val_accuracy: 0.6847 - 6s/epoch - 104ms/step
Epoch 156/200

Epoch 156: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7343 - accuracy: 0.6849 - val_loss: 0.7527 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 157/200

Epoch 157: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7337 - accuracy: 0.6853 - val_loss: 0.7488 - val_accuracy: 0.6807 - 6s/epoch - 105ms/step
Epoch 158/200

Epoch 158: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7362 - accuracy: 0.6871 - val_loss: 0.7447 - val_accuracy: 0.6813 - 6s/epoch - 104ms/step
Epoch 159/200

Epoch 159: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7335 - accuracy: 0.6854 - val_loss: 0.7465 - val_accuracy: 0.6733 - 6s/epoch - 104ms/step
Epoch 160/200

Epoch 160: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7344 - accuracy: 0.6846 - val_loss: 0.7469 - val_accuracy: 0.6787 - 6s/epoch - 104ms/step
Epoch 161/200

Epoch 161: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7344 - accuracy: 0.6838 - val_loss: 0.7483 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 162/200

Epoch 162: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7353 - accuracy: 0.6837 - val_loss: 0.7491 - val_accuracy: 0.6760 - 6s/epoch - 104ms/step
Epoch 163/200

Epoch 163: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7355 - accuracy: 0.6827 - val_loss: 0.7426 - val_accuracy: 0.6840 - 6s/epoch - 105ms/step
Epoch 164/200

Epoch 164: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7323 - accuracy: 0.6853 - val_loss: 0.7484 - val_accuracy: 0.6807 - 6s/epoch - 105ms/step
Epoch 165/200

Epoch 165: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7342 - accuracy: 0.6847 - val_loss: 0.7473 - val_accuracy: 0.6813 - 6s/epoch - 104ms/step
Epoch 166/200

Epoch 166: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7324 - accuracy: 0.6855 - val_loss: 0.7436 - val_accuracy: 0.6793 - 6s/epoch - 104ms/step
Epoch 167/200

Epoch 167: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7328 - accuracy: 0.6847 - val_loss: 0.7556 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 168/200

Epoch 168: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7303 - accuracy: 0.6856 - val_loss: 0.7486 - val_accuracy: 0.6807 - 6s/epoch - 104ms/step
Epoch 169/200

Epoch 169: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7346 - accuracy: 0.6856 - val_loss: 0.7546 - val_accuracy: 0.6820 - 6s/epoch - 104ms/step
Epoch 170/200

Epoch 170: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7334 - accuracy: 0.6861 - val_loss: 0.7539 - val_accuracy: 0.6780 - 6s/epoch - 105ms/step
Epoch 171/200

Epoch 171: val_accuracy did not improve from 0.68600
56/56 - 6s - loss: 0.7326 - accuracy: 0.6840 - val_loss: 0.7490 - val_accuracy: 0.6807 - 6s/epoch - 104ms/step
Epoch 172/200

Epoch 172: val_accuracy improved from 0.68600 to 0.68733, saving model to output/classifier_1.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.7316 - accuracy: 0.6847 - val_loss: 0.7401 - val_accuracy: 0.6873 - 32s/epoch - 580ms/step
Epoch 173/200

Epoch 173: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7320 - accuracy: 0.6842 - val_loss: 0.7479 - val_accuracy: 0.6833 - 6s/epoch - 105ms/step
Epoch 174/200

Epoch 174: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7318 - accuracy: 0.6853 - val_loss: 0.7492 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 175/200

Epoch 175: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7299 - accuracy: 0.6853 - val_loss: 0.7488 - val_accuracy: 0.6867 - 6s/epoch - 104ms/step
Epoch 176/200

Epoch 176: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7294 - accuracy: 0.6861 - val_loss: 0.7495 - val_accuracy: 0.6840 - 6s/epoch - 104ms/step
Epoch 177/200

Epoch 177: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7282 - accuracy: 0.6871 - val_loss: 0.7483 - val_accuracy: 0.6740 - 6s/epoch - 104ms/step
Epoch 178/200

Epoch 178: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7301 - accuracy: 0.6869 - val_loss: 0.7480 - val_accuracy: 0.6827 - 6s/epoch - 104ms/step
Epoch 179/200

Epoch 179: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7312 - accuracy: 0.6860 - val_loss: 0.7494 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 180/200

Epoch 180: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7330 - accuracy: 0.6842 - val_loss: 0.7495 - val_accuracy: 0.6833 - 6s/epoch - 104ms/step
Epoch 181/200

Epoch 181: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7310 - accuracy: 0.6870 - val_loss: 0.7539 - val_accuracy: 0.6727 - 6s/epoch - 104ms/step
Epoch 182/200

Epoch 182: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7316 - accuracy: 0.6863 - val_loss: 0.7484 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 183/200

Epoch 183: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7293 - accuracy: 0.6863 - val_loss: 0.7555 - val_accuracy: 0.6780 - 6s/epoch - 104ms/step
Epoch 184/200

Epoch 184: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7298 - accuracy: 0.6856 - val_loss: 0.7545 - val_accuracy: 0.6827 - 6s/epoch - 104ms/step
Epoch 185/200

Epoch 185: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7280 - accuracy: 0.6871 - val_loss: 0.7539 - val_accuracy: 0.6767 - 6s/epoch - 104ms/step
Epoch 186/200

Epoch 186: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7278 - accuracy: 0.6876 - val_loss: 0.7514 - val_accuracy: 0.6833 - 6s/epoch - 104ms/step
Epoch 187/200

Epoch 187: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7272 - accuracy: 0.6865 - val_loss: 0.7531 - val_accuracy: 0.6680 - 6s/epoch - 104ms/step
Epoch 188/200

Epoch 188: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7255 - accuracy: 0.6873 - val_loss: 0.7542 - val_accuracy: 0.6813 - 6s/epoch - 104ms/step
Epoch 189/200

Epoch 189: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7263 - accuracy: 0.6894 - val_loss: 0.7492 - val_accuracy: 0.6793 - 6s/epoch - 104ms/step
Epoch 190/200

Epoch 190: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7267 - accuracy: 0.6883 - val_loss: 0.7523 - val_accuracy: 0.6740 - 6s/epoch - 104ms/step
Epoch 191/200

Epoch 191: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7270 - accuracy: 0.6882 - val_loss: 0.7509 - val_accuracy: 0.6747 - 6s/epoch - 104ms/step
Epoch 192/200

Epoch 192: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7255 - accuracy: 0.6876 - val_loss: 0.7530 - val_accuracy: 0.6820 - 6s/epoch - 104ms/step
Epoch 193/200

Epoch 193: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7274 - accuracy: 0.6880 - val_loss: 0.7504 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Epoch 194/200

Epoch 194: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7242 - accuracy: 0.6876 - val_loss: 0.7520 - val_accuracy: 0.6687 - 6s/epoch - 104ms/step
Epoch 195/200

Epoch 195: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7263 - accuracy: 0.6882 - val_loss: 0.7485 - val_accuracy: 0.6833 - 6s/epoch - 104ms/step
Epoch 196/200

Epoch 196: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7246 - accuracy: 0.6871 - val_loss: 0.7547 - val_accuracy: 0.6833 - 6s/epoch - 104ms/step
Epoch 197/200

Epoch 197: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7249 - accuracy: 0.6883 - val_loss: 0.7495 - val_accuracy: 0.6813 - 6s/epoch - 105ms/step
Epoch 198/200

Epoch 198: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7245 - accuracy: 0.6893 - val_loss: 0.7492 - val_accuracy: 0.6860 - 6s/epoch - 105ms/step
Epoch 199/200

Epoch 199: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7249 - accuracy: 0.6877 - val_loss: 0.7487 - val_accuracy: 0.6827 - 6s/epoch - 104ms/step
Epoch 200/200

Epoch 200: val_accuracy did not improve from 0.68733
56/56 - 6s - loss: 0.7271 - accuracy: 0.6891 - val_loss: 0.7460 - val_accuracy: 0.6800 - 6s/epoch - 104ms/step
Script took 1999.8 seconds
-----
 Train classifier of type 2 
-----
2023-03-10 17:30:03.294721: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 17:30:04.685868: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 17:30:04.686730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 17:30:04.686841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 17:30:57.748404: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 17:30:58.428918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
Training DL with mtype=2 for 200 epochs with inter_train=True
Pad and normalise the data
Using 57000 training data samples
Using 1500 validation data samples
Train NN with seed=0 and model_type=2
Epoch 1/200
2023-03-10 17:31:06.168408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 17:31:06.512678: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.126873: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x2ac46800e500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-03-10 17:31:07.127128: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla P100-PCIE-12GB, Compute Capability 6.0
2023-03-10 17:31:07.135448: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-10 17:31:07.253506: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.336130: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-03-10 17:31:07.442266: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.789369: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.789616: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.790802: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.845513: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:07.984992: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:08.063768: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
2023-03-10 17:31:08.328160: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.

Epoch 1: val_accuracy improved from -inf to 0.59800, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 41s - loss: 1.4393 - accuracy: 0.4372 - val_loss: 1.1404 - val_accuracy: 0.5980 - 41s/epoch - 730ms/step
Epoch 2/200

Epoch 2: val_accuracy improved from 0.59800 to 0.74467, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.9536 - accuracy: 0.7130 - val_loss: 0.7991 - val_accuracy: 0.7447 - 31s/epoch - 555ms/step
Epoch 3/200

Epoch 3: val_accuracy improved from 0.74467 to 0.75600, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.7480 - accuracy: 0.7636 - val_loss: 0.7079 - val_accuracy: 0.7560 - 31s/epoch - 553ms/step
Epoch 4/200

Epoch 4: val_accuracy improved from 0.75600 to 0.76200, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.6704 - accuracy: 0.7736 - val_loss: 0.6454 - val_accuracy: 0.7620 - 31s/epoch - 559ms/step
Epoch 5/200

Epoch 5: val_accuracy improved from 0.76200 to 0.77067, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.6223 - accuracy: 0.7816 - val_loss: 0.6182 - val_accuracy: 0.7707 - 31s/epoch - 558ms/step
Epoch 6/200

Epoch 6: val_accuracy improved from 0.77067 to 0.77333, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.5908 - accuracy: 0.7864 - val_loss: 0.5924 - val_accuracy: 0.7733 - 31s/epoch - 554ms/step
Epoch 7/200

Epoch 7: val_accuracy improved from 0.77333 to 0.78133, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.5707 - accuracy: 0.7907 - val_loss: 0.5635 - val_accuracy: 0.7813 - 31s/epoch - 558ms/step
Epoch 8/200

Epoch 8: val_accuracy improved from 0.78133 to 0.78333, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.5545 - accuracy: 0.7933 - val_loss: 0.5438 - val_accuracy: 0.7833 - 31s/epoch - 556ms/step
Epoch 9/200

Epoch 9: val_accuracy did not improve from 0.78333
56/56 - 6s - loss: 0.5363 - accuracy: 0.7961 - val_loss: 0.5498 - val_accuracy: 0.7807 - 6s/epoch - 104ms/step
Epoch 10/200

Epoch 10: val_accuracy improved from 0.78333 to 0.78800, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.5262 - accuracy: 0.7982 - val_loss: 0.5228 - val_accuracy: 0.7880 - 31s/epoch - 557ms/step
Epoch 11/200

Epoch 11: val_accuracy improved from 0.78800 to 0.79067, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.5134 - accuracy: 0.8031 - val_loss: 0.5157 - val_accuracy: 0.7907 - 31s/epoch - 560ms/step
Epoch 12/200

Epoch 12: val_accuracy improved from 0.79067 to 0.79133, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.5070 - accuracy: 0.8033 - val_loss: 0.5111 - val_accuracy: 0.7913 - 31s/epoch - 560ms/step
Epoch 13/200

Epoch 13: val_accuracy improved from 0.79133 to 0.79200, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.4975 - accuracy: 0.8064 - val_loss: 0.5047 - val_accuracy: 0.7920 - 31s/epoch - 561ms/step
Epoch 14/200

Epoch 14: val_accuracy improved from 0.79200 to 0.79733, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 31s - loss: 0.4905 - accuracy: 0.8075 - val_loss: 0.5018 - val_accuracy: 0.7973 - 31s/epoch - 554ms/step
Epoch 15/200

Epoch 15: val_accuracy did not improve from 0.79733
56/56 - 6s - loss: 0.4847 - accuracy: 0.8106 - val_loss: 0.5058 - val_accuracy: 0.7927 - 6s/epoch - 105ms/step
Epoch 16/200

Epoch 16: val_accuracy did not improve from 0.79733
56/56 - 6s - loss: 0.4775 - accuracy: 0.8103 - val_loss: 0.4999 - val_accuracy: 0.7927 - 6s/epoch - 105ms/step
Epoch 17/200

Epoch 17: val_accuracy did not improve from 0.79733
56/56 - 6s - loss: 0.4700 - accuracy: 0.8119 - val_loss: 0.4855 - val_accuracy: 0.7973 - 6s/epoch - 105ms/step
Epoch 18/200

Epoch 18: val_accuracy did not improve from 0.79733
56/56 - 6s - loss: 0.4671 - accuracy: 0.8122 - val_loss: 0.4845 - val_accuracy: 0.7960 - 6s/epoch - 105ms/step
Epoch 19/200

Epoch 19: val_accuracy improved from 0.79733 to 0.80067, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.4616 - accuracy: 0.8127 - val_loss: 0.4677 - val_accuracy: 0.8007 - 32s/epoch - 567ms/step
Epoch 20/200

Epoch 20: val_accuracy did not improve from 0.80067
56/56 - 6s - loss: 0.4590 - accuracy: 0.8168 - val_loss: 0.4787 - val_accuracy: 0.7927 - 6s/epoch - 105ms/step
Epoch 21/200

Epoch 21: val_accuracy improved from 0.80067 to 0.80333, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.4533 - accuracy: 0.8171 - val_loss: 0.4639 - val_accuracy: 0.8033 - 32s/epoch - 573ms/step
Epoch 22/200

Epoch 22: val_accuracy did not improve from 0.80333
56/56 - 6s - loss: 0.4480 - accuracy: 0.8189 - val_loss: 0.4601 - val_accuracy: 0.7960 - 6s/epoch - 105ms/step
Epoch 23/200

Epoch 23: val_accuracy did not improve from 0.80333
56/56 - 6s - loss: 0.4488 - accuracy: 0.8180 - val_loss: 0.4677 - val_accuracy: 0.7947 - 6s/epoch - 105ms/step
Epoch 24/200

Epoch 24: val_accuracy did not improve from 0.80333
56/56 - 6s - loss: 0.4411 - accuracy: 0.8193 - val_loss: 0.4657 - val_accuracy: 0.8027 - 6s/epoch - 105ms/step
Epoch 25/200

Epoch 25: val_accuracy did not improve from 0.80333
56/56 - 6s - loss: 0.4404 - accuracy: 0.8195 - val_loss: 0.4573 - val_accuracy: 0.8013 - 6s/epoch - 105ms/step
Epoch 26/200

Epoch 26: val_accuracy did not improve from 0.80333
56/56 - 6s - loss: 0.4361 - accuracy: 0.8210 - val_loss: 0.4675 - val_accuracy: 0.7933 - 6s/epoch - 105ms/step
Epoch 27/200

Epoch 27: val_accuracy improved from 0.80333 to 0.80667, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.4315 - accuracy: 0.8232 - val_loss: 0.4508 - val_accuracy: 0.8067 - 32s/epoch - 580ms/step
Epoch 28/200

Epoch 28: val_accuracy did not improve from 0.80667
56/56 - 6s - loss: 0.4286 - accuracy: 0.8231 - val_loss: 0.4520 - val_accuracy: 0.8033 - 6s/epoch - 105ms/step
Epoch 29/200

Epoch 29: val_accuracy did not improve from 0.80667
56/56 - 6s - loss: 0.4265 - accuracy: 0.8236 - val_loss: 0.4500 - val_accuracy: 0.8067 - 6s/epoch - 105ms/step
Epoch 30/200

Epoch 30: val_accuracy improved from 0.80667 to 0.81133, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.4252 - accuracy: 0.8258 - val_loss: 0.4427 - val_accuracy: 0.8113 - 32s/epoch - 574ms/step
Epoch 31/200

Epoch 31: val_accuracy did not improve from 0.81133
56/56 - 6s - loss: 0.4209 - accuracy: 0.8269 - val_loss: 0.4269 - val_accuracy: 0.8113 - 6s/epoch - 105ms/step
Epoch 32/200

Epoch 32: val_accuracy did not improve from 0.81133
56/56 - 6s - loss: 0.4177 - accuracy: 0.8272 - val_loss: 0.4421 - val_accuracy: 0.8087 - 6s/epoch - 105ms/step
Epoch 33/200

Epoch 33: val_accuracy did not improve from 0.81133
56/56 - 6s - loss: 0.4167 - accuracy: 0.8281 - val_loss: 0.4273 - val_accuracy: 0.8093 - 6s/epoch - 106ms/step
Epoch 34/200

Epoch 34: val_accuracy did not improve from 0.81133
56/56 - 6s - loss: 0.4136 - accuracy: 0.8281 - val_loss: 0.4231 - val_accuracy: 0.8113 - 6s/epoch - 105ms/step
Epoch 35/200

Epoch 35: val_accuracy improved from 0.81133 to 0.81667, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.4096 - accuracy: 0.8292 - val_loss: 0.4196 - val_accuracy: 0.8167 - 32s/epoch - 571ms/step
Epoch 36/200

Epoch 36: val_accuracy did not improve from 0.81667
56/56 - 6s - loss: 0.4090 - accuracy: 0.8298 - val_loss: 0.4245 - val_accuracy: 0.8133 - 6s/epoch - 106ms/step
Epoch 37/200

Epoch 37: val_accuracy did not improve from 0.81667
56/56 - 6s - loss: 0.4052 - accuracy: 0.8317 - val_loss: 0.4315 - val_accuracy: 0.8153 - 6s/epoch - 105ms/step
Epoch 38/200

Epoch 38: val_accuracy did not improve from 0.81667
56/56 - 6s - loss: 0.4040 - accuracy: 0.8315 - val_loss: 0.4297 - val_accuracy: 0.8093 - 6s/epoch - 105ms/step
Epoch 39/200

Epoch 39: val_accuracy did not improve from 0.81667
56/56 - 6s - loss: 0.4027 - accuracy: 0.8312 - val_loss: 0.4221 - val_accuracy: 0.8140 - 6s/epoch - 104ms/step
Epoch 40/200

Epoch 40: val_accuracy did not improve from 0.81667
56/56 - 6s - loss: 0.4020 - accuracy: 0.8317 - val_loss: 0.4183 - val_accuracy: 0.8140 - 6s/epoch - 105ms/step
Epoch 41/200

Epoch 41: val_accuracy did not improve from 0.81667
56/56 - 6s - loss: 0.3989 - accuracy: 0.8329 - val_loss: 0.4221 - val_accuracy: 0.8147 - 6s/epoch - 105ms/step
Epoch 42/200

Epoch 42: val_accuracy improved from 0.81667 to 0.81867, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.3985 - accuracy: 0.8326 - val_loss: 0.4064 - val_accuracy: 0.8187 - 32s/epoch - 566ms/step
Epoch 43/200

Epoch 43: val_accuracy improved from 0.81867 to 0.82067, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.3954 - accuracy: 0.8341 - val_loss: 0.4192 - val_accuracy: 0.8207 - 32s/epoch - 577ms/step
Epoch 44/200

Epoch 44: val_accuracy did not improve from 0.82067
56/56 - 6s - loss: 0.3962 - accuracy: 0.8354 - val_loss: 0.4220 - val_accuracy: 0.8180 - 6s/epoch - 105ms/step
Epoch 45/200

Epoch 45: val_accuracy improved from 0.82067 to 0.82133, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 33s - loss: 0.3926 - accuracy: 0.8367 - val_loss: 0.4131 - val_accuracy: 0.8213 - 33s/epoch - 581ms/step
Epoch 46/200

Epoch 46: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3912 - accuracy: 0.8361 - val_loss: 0.4256 - val_accuracy: 0.8153 - 6s/epoch - 106ms/step
Epoch 47/200

Epoch 47: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3904 - accuracy: 0.8374 - val_loss: 0.4139 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 48/200

Epoch 48: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3905 - accuracy: 0.8344 - val_loss: 0.4062 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 49/200

Epoch 49: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3895 - accuracy: 0.8371 - val_loss: 0.4015 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 50/200

Epoch 50: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3872 - accuracy: 0.8365 - val_loss: 0.4095 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 51/200

Epoch 51: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3866 - accuracy: 0.8362 - val_loss: 0.4085 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 52/200

Epoch 52: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3860 - accuracy: 0.8375 - val_loss: 0.4097 - val_accuracy: 0.8207 - 6s/epoch - 105ms/step
Epoch 53/200

Epoch 53: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3853 - accuracy: 0.8382 - val_loss: 0.4241 - val_accuracy: 0.8173 - 6s/epoch - 105ms/step
Epoch 54/200

Epoch 54: val_accuracy did not improve from 0.82133
56/56 - 6s - loss: 0.3847 - accuracy: 0.8387 - val_loss: 0.3962 - val_accuracy: 0.8193 - 6s/epoch - 105ms/step
Epoch 55/200

Epoch 55: val_accuracy improved from 0.82133 to 0.82600, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 34s - loss: 0.3839 - accuracy: 0.8388 - val_loss: 0.4049 - val_accuracy: 0.8260 - 34s/epoch - 612ms/step
Epoch 56/200

Epoch 56: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3816 - accuracy: 0.8389 - val_loss: 0.4015 - val_accuracy: 0.8240 - 6s/epoch - 105ms/step
Epoch 57/200

Epoch 57: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3808 - accuracy: 0.8406 - val_loss: 0.3977 - val_accuracy: 0.8200 - 6s/epoch - 106ms/step
Epoch 58/200

Epoch 58: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3791 - accuracy: 0.8405 - val_loss: 0.4042 - val_accuracy: 0.8227 - 6s/epoch - 106ms/step
Epoch 59/200

Epoch 59: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3779 - accuracy: 0.8420 - val_loss: 0.3999 - val_accuracy: 0.8147 - 6s/epoch - 105ms/step
Epoch 60/200

Epoch 60: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3790 - accuracy: 0.8393 - val_loss: 0.4003 - val_accuracy: 0.8180 - 6s/epoch - 105ms/step
Epoch 61/200

Epoch 61: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3769 - accuracy: 0.8419 - val_loss: 0.4011 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 62/200

Epoch 62: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3761 - accuracy: 0.8416 - val_loss: 0.3943 - val_accuracy: 0.8187 - 6s/epoch - 106ms/step
Epoch 63/200

Epoch 63: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3745 - accuracy: 0.8421 - val_loss: 0.3967 - val_accuracy: 0.8193 - 6s/epoch - 105ms/step
Epoch 64/200

Epoch 64: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3756 - accuracy: 0.8422 - val_loss: 0.3938 - val_accuracy: 0.8200 - 6s/epoch - 106ms/step
Epoch 65/200

Epoch 65: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3746 - accuracy: 0.8418 - val_loss: 0.3992 - val_accuracy: 0.8200 - 6s/epoch - 105ms/step
Epoch 66/200

Epoch 66: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3745 - accuracy: 0.8423 - val_loss: 0.3998 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 67/200

Epoch 67: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3719 - accuracy: 0.8432 - val_loss: 0.3964 - val_accuracy: 0.8227 - 6s/epoch - 105ms/step
Epoch 68/200

Epoch 68: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3737 - accuracy: 0.8414 - val_loss: 0.4030 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 69/200

Epoch 69: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3712 - accuracy: 0.8429 - val_loss: 0.3985 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 70/200

Epoch 70: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3724 - accuracy: 0.8430 - val_loss: 0.3988 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 71/200

Epoch 71: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3691 - accuracy: 0.8436 - val_loss: 0.3969 - val_accuracy: 0.8167 - 6s/epoch - 106ms/step
Epoch 72/200

Epoch 72: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3713 - accuracy: 0.8432 - val_loss: 0.4104 - val_accuracy: 0.8160 - 6s/epoch - 106ms/step
Epoch 73/200

Epoch 73: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3709 - accuracy: 0.8444 - val_loss: 0.3934 - val_accuracy: 0.8220 - 6s/epoch - 105ms/step
Epoch 74/200

Epoch 74: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3682 - accuracy: 0.8441 - val_loss: 0.4034 - val_accuracy: 0.8187 - 6s/epoch - 106ms/step
Epoch 75/200

Epoch 75: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3678 - accuracy: 0.8452 - val_loss: 0.3960 - val_accuracy: 0.8193 - 6s/epoch - 105ms/step
Epoch 76/200

Epoch 76: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3665 - accuracy: 0.8445 - val_loss: 0.3957 - val_accuracy: 0.8173 - 6s/epoch - 105ms/step
Epoch 77/200

Epoch 77: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3678 - accuracy: 0.8457 - val_loss: 0.3974 - val_accuracy: 0.8167 - 6s/epoch - 106ms/step
Epoch 78/200

Epoch 78: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3656 - accuracy: 0.8457 - val_loss: 0.3916 - val_accuracy: 0.8227 - 6s/epoch - 106ms/step
Epoch 79/200

Epoch 79: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3650 - accuracy: 0.8463 - val_loss: 0.3946 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 80/200

Epoch 80: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3637 - accuracy: 0.8454 - val_loss: 0.4051 - val_accuracy: 0.8200 - 6s/epoch - 106ms/step
Epoch 81/200

Epoch 81: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3647 - accuracy: 0.8459 - val_loss: 0.3998 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 82/200

Epoch 82: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3650 - accuracy: 0.8453 - val_loss: 0.3970 - val_accuracy: 0.8167 - 6s/epoch - 106ms/step
Epoch 83/200

Epoch 83: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3661 - accuracy: 0.8451 - val_loss: 0.3969 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 84/200

Epoch 84: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3623 - accuracy: 0.8474 - val_loss: 0.3965 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 85/200

Epoch 85: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3638 - accuracy: 0.8462 - val_loss: 0.3979 - val_accuracy: 0.8167 - 6s/epoch - 106ms/step
Epoch 86/200

Epoch 86: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3622 - accuracy: 0.8466 - val_loss: 0.3980 - val_accuracy: 0.8187 - 6s/epoch - 106ms/step
Epoch 87/200

Epoch 87: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3644 - accuracy: 0.8471 - val_loss: 0.3970 - val_accuracy: 0.8193 - 6s/epoch - 105ms/step
Epoch 88/200

Epoch 88: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3603 - accuracy: 0.8473 - val_loss: 0.4041 - val_accuracy: 0.8167 - 6s/epoch - 106ms/step
Epoch 89/200

Epoch 89: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3621 - accuracy: 0.8476 - val_loss: 0.3954 - val_accuracy: 0.8220 - 6s/epoch - 105ms/step
Epoch 90/200

Epoch 90: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3588 - accuracy: 0.8487 - val_loss: 0.3951 - val_accuracy: 0.8187 - 6s/epoch - 105ms/step
Epoch 91/200

Epoch 91: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3601 - accuracy: 0.8488 - val_loss: 0.3951 - val_accuracy: 0.8200 - 6s/epoch - 106ms/step
Epoch 92/200

Epoch 92: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3601 - accuracy: 0.8474 - val_loss: 0.3922 - val_accuracy: 0.8200 - 6s/epoch - 105ms/step
Epoch 93/200

Epoch 93: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3619 - accuracy: 0.8472 - val_loss: 0.3987 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 94/200

Epoch 94: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3594 - accuracy: 0.8473 - val_loss: 0.3983 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 95/200

Epoch 95: val_accuracy did not improve from 0.82600
56/56 - 6s - loss: 0.3602 - accuracy: 0.8471 - val_loss: 0.3961 - val_accuracy: 0.8140 - 6s/epoch - 105ms/step
Epoch 96/200

Epoch 96: val_accuracy improved from 0.82600 to 0.82667, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 34s - loss: 0.3581 - accuracy: 0.8483 - val_loss: 0.3939 - val_accuracy: 0.8267 - 34s/epoch - 609ms/step
Epoch 97/200

Epoch 97: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3564 - accuracy: 0.8478 - val_loss: 0.3961 - val_accuracy: 0.8207 - 6s/epoch - 106ms/step
Epoch 98/200

Epoch 98: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3579 - accuracy: 0.8491 - val_loss: 0.4009 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 99/200

Epoch 99: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3572 - accuracy: 0.8478 - val_loss: 0.4002 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 100/200

Epoch 100: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3556 - accuracy: 0.8495 - val_loss: 0.4056 - val_accuracy: 0.8207 - 6s/epoch - 106ms/step
Epoch 101/200

Epoch 101: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3555 - accuracy: 0.8488 - val_loss: 0.3976 - val_accuracy: 0.8240 - 6s/epoch - 106ms/step
Epoch 102/200

Epoch 102: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3552 - accuracy: 0.8490 - val_loss: 0.3953 - val_accuracy: 0.8227 - 6s/epoch - 106ms/step
Epoch 103/200

Epoch 103: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3551 - accuracy: 0.8488 - val_loss: 0.3999 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 104/200

Epoch 104: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3551 - accuracy: 0.8488 - val_loss: 0.4047 - val_accuracy: 0.8187 - 6s/epoch - 106ms/step
Epoch 105/200

Epoch 105: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3557 - accuracy: 0.8488 - val_loss: 0.3966 - val_accuracy: 0.8207 - 6s/epoch - 106ms/step
Epoch 106/200

Epoch 106: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3524 - accuracy: 0.8503 - val_loss: 0.3937 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 107/200

Epoch 107: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3521 - accuracy: 0.8507 - val_loss: 0.4015 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 108/200

Epoch 108: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3527 - accuracy: 0.8515 - val_loss: 0.4005 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 109/200

Epoch 109: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3541 - accuracy: 0.8493 - val_loss: 0.3954 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 110/200

Epoch 110: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3533 - accuracy: 0.8503 - val_loss: 0.3954 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 111/200

Epoch 111: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3523 - accuracy: 0.8511 - val_loss: 0.4048 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 112/200

Epoch 112: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3522 - accuracy: 0.8506 - val_loss: 0.3981 - val_accuracy: 0.8260 - 6s/epoch - 105ms/step
Epoch 113/200

Epoch 113: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3516 - accuracy: 0.8513 - val_loss: 0.3948 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 114/200

Epoch 114: val_accuracy did not improve from 0.82667
56/56 - 6s - loss: 0.3523 - accuracy: 0.8495 - val_loss: 0.3950 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 115/200

Epoch 115: val_accuracy improved from 0.82667 to 0.82733, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 34s - loss: 0.3504 - accuracy: 0.8505 - val_loss: 0.3949 - val_accuracy: 0.8273 - 34s/epoch - 609ms/step
Epoch 116/200

Epoch 116: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3501 - accuracy: 0.8526 - val_loss: 0.3957 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 117/200

Epoch 117: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3501 - accuracy: 0.8519 - val_loss: 0.3961 - val_accuracy: 0.8187 - 6s/epoch - 106ms/step
Epoch 118/200

Epoch 118: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3492 - accuracy: 0.8520 - val_loss: 0.3943 - val_accuracy: 0.8253 - 6s/epoch - 106ms/step
Epoch 119/200

Epoch 119: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3507 - accuracy: 0.8514 - val_loss: 0.4046 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 120/200

Epoch 120: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3499 - accuracy: 0.8515 - val_loss: 0.4006 - val_accuracy: 0.8227 - 6s/epoch - 105ms/step
Epoch 121/200

Epoch 121: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3508 - accuracy: 0.8511 - val_loss: 0.3908 - val_accuracy: 0.8227 - 6s/epoch - 106ms/step
Epoch 122/200

Epoch 122: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3480 - accuracy: 0.8534 - val_loss: 0.3958 - val_accuracy: 0.8193 - 6s/epoch - 106ms/step
Epoch 123/200

Epoch 123: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3492 - accuracy: 0.8522 - val_loss: 0.4000 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 124/200

Epoch 124: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3496 - accuracy: 0.8520 - val_loss: 0.4040 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 125/200

Epoch 125: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3470 - accuracy: 0.8519 - val_loss: 0.3998 - val_accuracy: 0.8233 - 6s/epoch - 105ms/step
Epoch 126/200

Epoch 126: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3488 - accuracy: 0.8508 - val_loss: 0.3936 - val_accuracy: 0.8233 - 6s/epoch - 105ms/step
Epoch 127/200

Epoch 127: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3470 - accuracy: 0.8529 - val_loss: 0.3964 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 128/200

Epoch 128: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3474 - accuracy: 0.8524 - val_loss: 0.4060 - val_accuracy: 0.8253 - 6s/epoch - 106ms/step
Epoch 129/200

Epoch 129: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3444 - accuracy: 0.8531 - val_loss: 0.4015 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 130/200

Epoch 130: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3456 - accuracy: 0.8534 - val_loss: 0.3957 - val_accuracy: 0.8267 - 6s/epoch - 105ms/step
Epoch 131/200

Epoch 131: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3441 - accuracy: 0.8544 - val_loss: 0.4000 - val_accuracy: 0.8227 - 6s/epoch - 106ms/step
Epoch 132/200

Epoch 132: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3454 - accuracy: 0.8532 - val_loss: 0.3987 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 133/200

Epoch 133: val_accuracy did not improve from 0.82733
56/56 - 6s - loss: 0.3435 - accuracy: 0.8529 - val_loss: 0.4023 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 134/200

Epoch 134: val_accuracy improved from 0.82733 to 0.82867, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 34s - loss: 0.3440 - accuracy: 0.8533 - val_loss: 0.4040 - val_accuracy: 0.8287 - 34s/epoch - 611ms/step
Epoch 135/200

Epoch 135: val_accuracy did not improve from 0.82867
56/56 - 6s - loss: 0.3462 - accuracy: 0.8526 - val_loss: 0.4035 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 136/200

Epoch 136: val_accuracy did not improve from 0.82867
56/56 - 6s - loss: 0.3443 - accuracy: 0.8543 - val_loss: 0.3997 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 137/200

Epoch 137: val_accuracy did not improve from 0.82867
56/56 - 6s - loss: 0.3454 - accuracy: 0.8538 - val_loss: 0.3962 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 138/200

Epoch 138: val_accuracy improved from 0.82867 to 0.82933, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 32s - loss: 0.3430 - accuracy: 0.8535 - val_loss: 0.3993 - val_accuracy: 0.8293 - 32s/epoch - 574ms/step
Epoch 139/200

Epoch 139: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3439 - accuracy: 0.8532 - val_loss: 0.3994 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 140/200

Epoch 140: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3434 - accuracy: 0.8535 - val_loss: 0.3969 - val_accuracy: 0.8193 - 6s/epoch - 105ms/step
Epoch 141/200

Epoch 141: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3447 - accuracy: 0.8542 - val_loss: 0.4111 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 142/200

Epoch 142: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3414 - accuracy: 0.8549 - val_loss: 0.4001 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 143/200

Epoch 143: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3416 - accuracy: 0.8546 - val_loss: 0.4011 - val_accuracy: 0.8260 - 6s/epoch - 105ms/step
Epoch 144/200

Epoch 144: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3397 - accuracy: 0.8540 - val_loss: 0.3981 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 145/200

Epoch 145: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3428 - accuracy: 0.8532 - val_loss: 0.4016 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 146/200

Epoch 146: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3387 - accuracy: 0.8562 - val_loss: 0.3999 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 147/200

Epoch 147: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3415 - accuracy: 0.8532 - val_loss: 0.4015 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 148/200

Epoch 148: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3396 - accuracy: 0.8545 - val_loss: 0.4020 - val_accuracy: 0.8280 - 6s/epoch - 106ms/step
Epoch 149/200

Epoch 149: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3416 - accuracy: 0.8548 - val_loss: 0.4008 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 150/200

Epoch 150: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3423 - accuracy: 0.8536 - val_loss: 0.4015 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 151/200

Epoch 151: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3394 - accuracy: 0.8558 - val_loss: 0.4032 - val_accuracy: 0.8293 - 6s/epoch - 105ms/step
Epoch 152/200

Epoch 152: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3393 - accuracy: 0.8557 - val_loss: 0.3997 - val_accuracy: 0.8273 - 6s/epoch - 106ms/step
Epoch 153/200

Epoch 153: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3394 - accuracy: 0.8567 - val_loss: 0.4043 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 154/200

Epoch 154: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3387 - accuracy: 0.8549 - val_loss: 0.3999 - val_accuracy: 0.8273 - 6s/epoch - 106ms/step
Epoch 155/200

Epoch 155: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3392 - accuracy: 0.8554 - val_loss: 0.4044 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 156/200

Epoch 156: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3378 - accuracy: 0.8572 - val_loss: 0.4034 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 157/200

Epoch 157: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3370 - accuracy: 0.8560 - val_loss: 0.3956 - val_accuracy: 0.8273 - 6s/epoch - 106ms/step
Epoch 158/200

Epoch 158: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3360 - accuracy: 0.8572 - val_loss: 0.4024 - val_accuracy: 0.8227 - 6s/epoch - 105ms/step
Epoch 159/200

Epoch 159: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3380 - accuracy: 0.8553 - val_loss: 0.4021 - val_accuracy: 0.8273 - 6s/epoch - 106ms/step
Epoch 160/200

Epoch 160: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3369 - accuracy: 0.8559 - val_loss: 0.4018 - val_accuracy: 0.8213 - 6s/epoch - 105ms/step
Epoch 161/200

Epoch 161: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3374 - accuracy: 0.8553 - val_loss: 0.4038 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 162/200

Epoch 162: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3357 - accuracy: 0.8581 - val_loss: 0.4019 - val_accuracy: 0.8247 - 6s/epoch - 105ms/step
Epoch 163/200

Epoch 163: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3371 - accuracy: 0.8550 - val_loss: 0.3995 - val_accuracy: 0.8233 - 6s/epoch - 105ms/step
Epoch 164/200

Epoch 164: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3350 - accuracy: 0.8553 - val_loss: 0.4079 - val_accuracy: 0.8240 - 6s/epoch - 106ms/step
Epoch 165/200

Epoch 165: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3366 - accuracy: 0.8563 - val_loss: 0.3973 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 166/200

Epoch 166: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3366 - accuracy: 0.8566 - val_loss: 0.4079 - val_accuracy: 0.8253 - 6s/epoch - 105ms/step
Epoch 167/200

Epoch 167: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3343 - accuracy: 0.8563 - val_loss: 0.4059 - val_accuracy: 0.8293 - 6s/epoch - 106ms/step
Epoch 168/200

Epoch 168: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3356 - accuracy: 0.8563 - val_loss: 0.4031 - val_accuracy: 0.8233 - 6s/epoch - 105ms/step
Epoch 169/200

Epoch 169: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3354 - accuracy: 0.8552 - val_loss: 0.4057 - val_accuracy: 0.8273 - 6s/epoch - 106ms/step
Epoch 170/200

Epoch 170: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3345 - accuracy: 0.8573 - val_loss: 0.4001 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 171/200

Epoch 171: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3336 - accuracy: 0.8579 - val_loss: 0.4145 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 172/200

Epoch 172: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3347 - accuracy: 0.8573 - val_loss: 0.3978 - val_accuracy: 0.8260 - 6s/epoch - 105ms/step
Epoch 173/200

Epoch 173: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3329 - accuracy: 0.8577 - val_loss: 0.4058 - val_accuracy: 0.8193 - 6s/epoch - 105ms/step
Epoch 174/200

Epoch 174: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3327 - accuracy: 0.8574 - val_loss: 0.4096 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 175/200

Epoch 175: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3323 - accuracy: 0.8580 - val_loss: 0.4109 - val_accuracy: 0.8220 - 6s/epoch - 106ms/step
Epoch 176/200

Epoch 176: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3314 - accuracy: 0.8587 - val_loss: 0.4019 - val_accuracy: 0.8253 - 6s/epoch - 106ms/step
Epoch 177/200

Epoch 177: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3312 - accuracy: 0.8584 - val_loss: 0.4013 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 178/200

Epoch 178: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3324 - accuracy: 0.8587 - val_loss: 0.4011 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 179/200

Epoch 179: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3322 - accuracy: 0.8566 - val_loss: 0.4111 - val_accuracy: 0.8267 - 6s/epoch - 105ms/step
Epoch 180/200

Epoch 180: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3333 - accuracy: 0.8575 - val_loss: 0.4100 - val_accuracy: 0.8220 - 6s/epoch - 105ms/step
Epoch 181/200

Epoch 181: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3346 - accuracy: 0.8566 - val_loss: 0.4125 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 182/200

Epoch 182: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3312 - accuracy: 0.8579 - val_loss: 0.4177 - val_accuracy: 0.8220 - 6s/epoch - 105ms/step
Epoch 183/200

Epoch 183: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3309 - accuracy: 0.8577 - val_loss: 0.4262 - val_accuracy: 0.8227 - 6s/epoch - 105ms/step
Epoch 184/200

Epoch 184: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3314 - accuracy: 0.8584 - val_loss: 0.4104 - val_accuracy: 0.8240 - 6s/epoch - 106ms/step
Epoch 185/200

Epoch 185: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3323 - accuracy: 0.8593 - val_loss: 0.4065 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 186/200

Epoch 186: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3310 - accuracy: 0.8584 - val_loss: 0.4096 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Epoch 187/200

Epoch 187: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3313 - accuracy: 0.8573 - val_loss: 0.4119 - val_accuracy: 0.8247 - 6s/epoch - 105ms/step
Epoch 188/200

Epoch 188: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3304 - accuracy: 0.8603 - val_loss: 0.4043 - val_accuracy: 0.8227 - 6s/epoch - 106ms/step
Epoch 189/200

Epoch 189: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3312 - accuracy: 0.8585 - val_loss: 0.4069 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 190/200

Epoch 190: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3309 - accuracy: 0.8596 - val_loss: 0.4134 - val_accuracy: 0.8247 - 6s/epoch - 106ms/step
Epoch 191/200

Epoch 191: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3291 - accuracy: 0.8588 - val_loss: 0.4051 - val_accuracy: 0.8240 - 6s/epoch - 106ms/step
Epoch 192/200

Epoch 192: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3287 - accuracy: 0.8603 - val_loss: 0.4124 - val_accuracy: 0.8233 - 6s/epoch - 106ms/step
Epoch 193/200

Epoch 193: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3294 - accuracy: 0.8606 - val_loss: 0.4110 - val_accuracy: 0.8260 - 6s/epoch - 106ms/step
Epoch 194/200

Epoch 194: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3278 - accuracy: 0.8595 - val_loss: 0.4144 - val_accuracy: 0.8213 - 6s/epoch - 106ms/step
Epoch 195/200

Epoch 195: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3297 - accuracy: 0.8591 - val_loss: 0.4089 - val_accuracy: 0.8200 - 6s/epoch - 105ms/step
Epoch 196/200

Epoch 196: val_accuracy did not improve from 0.82933
56/56 - 6s - loss: 0.3269 - accuracy: 0.8588 - val_loss: 0.4099 - val_accuracy: 0.8280 - 6s/epoch - 105ms/step
Epoch 197/200

Epoch 197: val_accuracy improved from 0.82933 to 0.83000, saving model to output/classifier_2.pkl
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.
56/56 - 35s - loss: 0.3298 - accuracy: 0.8592 - val_loss: 0.4023 - val_accuracy: 0.8300 - 35s/epoch - 622ms/step
Epoch 198/200

Epoch 198: val_accuracy did not improve from 0.83000
56/56 - 6s - loss: 0.3284 - accuracy: 0.8604 - val_loss: 0.4114 - val_accuracy: 0.8253 - 6s/epoch - 106ms/step
Epoch 199/200

Epoch 199: val_accuracy did not improve from 0.83000
56/56 - 6s - loss: 0.3290 - accuracy: 0.8586 - val_loss: 0.4114 - val_accuracy: 0.8200 - 6s/epoch - 106ms/step
Epoch 200/200

Epoch 200: val_accuracy did not improve from 0.83000
56/56 - 6s - loss: 0.3279 - accuracy: 0.8592 - val_loss: 0.4110 - val_accuracy: 0.8267 - 6s/epoch - 106ms/step
Script took 1956.5 seconds
-----
 Get F1 scores on test data 
-----
2023-03-10 18:02:45.642052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:02:47.210721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:02:47.211418: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:02:47.211489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 18:02:52.009854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:02:52.811217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 18:04:04.845700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 18:04:05.226878: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
   1/1782 [..............................] - ETA: 1:25:24   7/1782 [..............................] - ETA: 17s      13/1782 [..............................] - ETA: 17s  19/1782 [..............................] - ETA: 17s  25/1782 [..............................] - ETA: 17s  31/1782 [..............................] - ETA: 17s  37/1782 [..............................] - ETA: 16s  43/1782 [..............................] - ETA: 16s  49/1782 [..............................] - ETA: 16s  55/1782 [..............................] - ETA: 16s  61/1782 [>.............................] - ETA: 16s  67/1782 [>.............................] - ETA: 16s  73/1782 [>.............................] - ETA: 16s  79/1782 [>.............................] - ETA: 16s  85/1782 [>.............................] - ETA: 16s  91/1782 [>.............................] - ETA: 16s  97/1782 [>.............................] - ETA: 16s 103/1782 [>.............................] - ETA: 16s 109/1782 [>.............................] - ETA: 16s 115/1782 [>.............................] - ETA: 15s 121/1782 [=>............................] - ETA: 15s 127/1782 [=>............................] - ETA: 15s 133/1782 [=>............................] - ETA: 15s 139/1782 [=>............................] - ETA: 15s 145/1782 [=>............................] - ETA: 15s 151/1782 [=>............................] - ETA: 15s 157/1782 [=>............................] - ETA: 15s 163/1782 [=>............................] - ETA: 15s 169/1782 [=>............................] - ETA: 15s 175/1782 [=>............................] - ETA: 15s 181/1782 [==>...........................] - ETA: 15s 187/1782 [==>...........................] - ETA: 15s 193/1782 [==>...........................] - ETA: 15s 199/1782 [==>...........................] - ETA: 15s 205/1782 [==>...........................] - ETA: 15s 211/1782 [==>...........................] - ETA: 14s 217/1782 [==>...........................] - ETA: 14s 223/1782 [==>...........................] - ETA: 14s 229/1782 [==>...........................] - ETA: 14s 235/1782 [==>...........................] - ETA: 14s 241/1782 [===>..........................] - ETA: 14s 247/1782 [===>..........................] - ETA: 14s 253/1782 [===>..........................] - ETA: 14s 259/1782 [===>..........................] - ETA: 14s 265/1782 [===>..........................] - ETA: 14s 271/1782 [===>..........................] - ETA: 14s 277/1782 [===>..........................] - ETA: 14s 283/1782 [===>..........................] - ETA: 14s 289/1782 [===>..........................] - ETA: 14s 295/1782 [===>..........................] - ETA: 14s 301/1782 [====>.........................] - ETA: 14s 307/1782 [====>.........................] - ETA: 14s 313/1782 [====>.........................] - ETA: 13s 319/1782 [====>.........................] - ETA: 13s 325/1782 [====>.........................] - ETA: 13s 331/1782 [====>.........................] - ETA: 13s 337/1782 [====>.........................] - ETA: 13s 343/1782 [====>.........................] - ETA: 13s 349/1782 [====>.........................] - ETA: 13s 355/1782 [====>.........................] - ETA: 13s 361/1782 [=====>........................] - ETA: 13s 367/1782 [=====>........................] - ETA: 13s 373/1782 [=====>........................] - ETA: 13s 379/1782 [=====>........................] - ETA: 13s 385/1782 [=====>........................] - ETA: 13s 391/1782 [=====>........................] - ETA: 13s 397/1782 [=====>........................] - ETA: 13s 403/1782 [=====>........................] - ETA: 13s 409/1782 [=====>........................] - ETA: 13s 415/1782 [=====>........................] - ETA: 12s 421/1782 [======>.......................] - ETA: 12s 427/1782 [======>.......................] - ETA: 12s 433/1782 [======>.......................] - ETA: 12s 439/1782 [======>.......................] - ETA: 12s 445/1782 [======>.......................] - ETA: 12s 451/1782 [======>.......................] - ETA: 12s 457/1782 [======>.......................] - ETA: 12s 463/1782 [======>.......................] - ETA: 12s 469/1782 [======>.......................] - ETA: 12s 475/1782 [======>.......................] - ETA: 12s 481/1782 [=======>......................] - ETA: 12s 487/1782 [=======>......................] - ETA: 12s 493/1782 [=======>......................] - ETA: 12s 499/1782 [=======>......................] - ETA: 12s 505/1782 [=======>......................] - ETA: 12s 511/1782 [=======>......................] - ETA: 12s 517/1782 [=======>......................] - ETA: 12s 523/1782 [=======>......................] - ETA: 11s 529/1782 [=======>......................] - ETA: 11s 535/1782 [========>.....................] - ETA: 11s 541/1782 [========>.....................] - ETA: 11s 547/1782 [========>.....................] - ETA: 11s 553/1782 [========>.....................] - ETA: 11s 559/1782 [========>.....................] - ETA: 11s 565/1782 [========>.....................] - ETA: 11s 571/1782 [========>.....................] - ETA: 11s 577/1782 [========>.....................] - ETA: 11s 583/1782 [========>.....................] - ETA: 11s 589/1782 [========>.....................] - ETA: 11s 595/1782 [=========>....................] - ETA: 11s 601/1782 [=========>....................] - ETA: 11s 607/1782 [=========>....................] - ETA: 11s 613/1782 [=========>....................] - ETA: 11s 619/1782 [=========>....................] - ETA: 11s 625/1782 [=========>....................] - ETA: 10s 631/1782 [=========>....................] - ETA: 10s 637/1782 [=========>....................] - ETA: 10s 643/1782 [=========>....................] - ETA: 10s 649/1782 [=========>....................] - ETA: 10s 655/1782 [==========>...................] - ETA: 10s 661/1782 [==========>...................] - ETA: 10s 667/1782 [==========>...................] - ETA: 10s 673/1782 [==========>...................] - ETA: 10s 679/1782 [==========>...................] - ETA: 10s 685/1782 [==========>...................] - ETA: 10s 691/1782 [==========>...................] - ETA: 10s 697/1782 [==========>...................] - ETA: 10s 703/1782 [==========>...................] - ETA: 10s 709/1782 [==========>...................] - ETA: 10s 715/1782 [===========>..................] - ETA: 10s 721/1782 [===========>..................] - ETA: 10s 727/1782 [===========>..................] - ETA: 9s  733/1782 [===========>..................] - ETA: 9s 739/1782 [===========>..................] - ETA: 9s 745/1782 [===========>..................] - ETA: 9s 751/1782 [===========>..................] - ETA: 9s 756/1782 [===========>..................] - ETA: 9s 762/1782 [===========>..................] - ETA: 9s 768/1782 [===========>..................] - ETA: 9s 774/1782 [============>.................] - ETA: 9s 780/1782 [============>.................] - ETA: 9s 786/1782 [============>.................] - ETA: 9s 792/1782 [============>.................] - ETA: 9s 798/1782 [============>.................] - ETA: 9s 804/1782 [============>.................] - ETA: 9s 810/1782 [============>.................] - ETA: 9s 816/1782 [============>.................] - ETA: 9s 822/1782 [============>.................] - ETA: 9s 828/1782 [============>.................] - ETA: 9s 834/1782 [=============>................] - ETA: 8s 840/1782 [=============>................] - ETA: 8s 846/1782 [=============>................] - ETA: 8s 852/1782 [=============>................] - ETA: 8s 858/1782 [=============>................] - ETA: 8s 864/1782 [=============>................] - ETA: 8s 870/1782 [=============>................] - ETA: 8s 876/1782 [=============>................] - ETA: 8s 882/1782 [=============>................] - ETA: 8s 888/1782 [=============>................] - ETA: 8s 894/1782 [==============>...............] - ETA: 8s 900/1782 [==============>...............] - ETA: 8s 906/1782 [==============>...............] - ETA: 8s 912/1782 [==============>...............] - ETA: 8s 918/1782 [==============>...............] - ETA: 8s 924/1782 [==============>...............] - ETA: 8s 930/1782 [==============>...............] - ETA: 8s 936/1782 [==============>...............] - ETA: 8s 942/1782 [==============>...............] - ETA: 7s 948/1782 [==============>...............] - ETA: 7s 954/1782 [===============>..............] - ETA: 7s 960/1782 [===============>..............] - ETA: 7s 966/1782 [===============>..............] - ETA: 7s 972/1782 [===============>..............] - ETA: 7s 978/1782 [===============>..............] - ETA: 7s 984/1782 [===============>..............] - ETA: 7s 990/1782 [===============>..............] - ETA: 7s 996/1782 [===============>..............] - ETA: 7s1002/1782 [===============>..............] - ETA: 7s1008/1782 [===============>..............] - ETA: 7s1014/1782 [================>.............] - ETA: 7s1020/1782 [================>.............] - ETA: 7s1026/1782 [================>.............] - ETA: 7s1032/1782 [================>.............] - ETA: 7s1038/1782 [================>.............] - ETA: 7s1044/1782 [================>.............] - ETA: 6s1050/1782 [================>.............] - ETA: 6s1056/1782 [================>.............] - ETA: 6s1062/1782 [================>.............] - ETA: 6s1068/1782 [================>.............] - ETA: 6s1074/1782 [=================>............] - ETA: 6s1080/1782 [=================>............] - ETA: 6s1086/1782 [=================>............] - ETA: 6s1092/1782 [=================>............] - ETA: 6s1098/1782 [=================>............] - ETA: 6s1104/1782 [=================>............] - ETA: 6s1110/1782 [=================>............] - ETA: 6s1116/1782 [=================>............] - ETA: 6s1122/1782 [=================>............] - ETA: 6s1128/1782 [=================>............] - ETA: 6s1134/1782 [==================>...........] - ETA: 6s1140/1782 [==================>...........] - ETA: 6s1146/1782 [==================>...........] - ETA: 6s1152/1782 [==================>...........] - ETA: 5s1158/1782 [==================>...........] - ETA: 5s1164/1782 [==================>...........] - ETA: 5s1170/1782 [==================>...........] - ETA: 5s1176/1782 [==================>...........] - ETA: 5s1182/1782 [==================>...........] - ETA: 5s1188/1782 [===================>..........] - ETA: 5s1194/1782 [===================>..........] - ETA: 5s1200/1782 [===================>..........] - ETA: 5s1206/1782 [===================>..........] - ETA: 5s1212/1782 [===================>..........] - ETA: 5s1218/1782 [===================>..........] - ETA: 5s1224/1782 [===================>..........] - ETA: 5s1230/1782 [===================>..........] - ETA: 5s1236/1782 [===================>..........] - ETA: 5s1242/1782 [===================>..........] - ETA: 5s1248/1782 [====================>.........] - ETA: 5s1254/1782 [====================>.........] - ETA: 4s1260/1782 [====================>.........] - ETA: 4s1266/1782 [====================>.........] - ETA: 4s1272/1782 [====================>.........] - ETA: 4s1278/1782 [====================>.........] - ETA: 4s1284/1782 [====================>.........] - ETA: 4s1290/1782 [====================>.........] - ETA: 4s1296/1782 [====================>.........] - ETA: 4s1302/1782 [====================>.........] - ETA: 4s1308/1782 [=====================>........] - ETA: 4s1314/1782 [=====================>........] - ETA: 4s1320/1782 [=====================>........] - ETA: 4s1326/1782 [=====================>........] - ETA: 4s1332/1782 [=====================>........] - ETA: 4s1338/1782 [=====================>........] - ETA: 4s1344/1782 [=====================>........] - ETA: 4s1350/1782 [=====================>........] - ETA: 4s1356/1782 [=====================>........] - ETA: 4s1362/1782 [=====================>........] - ETA: 3s1368/1782 [======================>.......] - ETA: 3s1374/1782 [======================>.......] - ETA: 3s1380/1782 [======================>.......] - ETA: 3s1386/1782 [======================>.......] - ETA: 3s1392/1782 [======================>.......] - ETA: 3s1398/1782 [======================>.......] - ETA: 3s1404/1782 [======================>.......] - ETA: 3s1410/1782 [======================>.......] - ETA: 3s1416/1782 [======================>.......] - ETA: 3s1422/1782 [======================>.......] - ETA: 3s1428/1782 [=======================>......] - ETA: 3s1434/1782 [=======================>......] - ETA: 3s1440/1782 [=======================>......] - ETA: 3s1446/1782 [=======================>......] - ETA: 3s1452/1782 [=======================>......] - ETA: 3s1458/1782 [=======================>......] - ETA: 3s1464/1782 [=======================>......] - ETA: 3s1470/1782 [=======================>......] - ETA: 2s1476/1782 [=======================>......] - ETA: 2s1482/1782 [=======================>......] - ETA: 2s1488/1782 [========================>.....] - ETA: 2s1494/1782 [========================>.....] - ETA: 2s1500/1782 [========================>.....] - ETA: 2s1506/1782 [========================>.....] - ETA: 2s1512/1782 [========================>.....] - ETA: 2s1518/1782 [========================>.....] - ETA: 2s1524/1782 [========================>.....] - ETA: 2s1530/1782 [========================>.....] - ETA: 2s1536/1782 [========================>.....] - ETA: 2s1542/1782 [========================>.....] - ETA: 2s1548/1782 [=========================>....] - ETA: 2s1554/1782 [=========================>....] - ETA: 2s1560/1782 [=========================>....] - ETA: 2s1566/1782 [=========================>....] - ETA: 2s1572/1782 [=========================>....] - ETA: 1s1578/1782 [=========================>....] - ETA: 1s1584/1782 [=========================>....] - ETA: 1s1590/1782 [=========================>....] - ETA: 1s1596/1782 [=========================>....] - ETA: 1s1602/1782 [=========================>....] - ETA: 1s1608/1782 [==========================>...] - ETA: 1s1614/1782 [==========================>...] - ETA: 1s1620/1782 [==========================>...] - ETA: 1s1626/1782 [==========================>...] - ETA: 1s1632/1782 [==========================>...] - ETA: 1s1638/1782 [==========================>...] - ETA: 1s1644/1782 [==========================>...] - ETA: 1s1650/1782 [==========================>...] - ETA: 1s1656/1782 [==========================>...] - ETA: 1s1662/1782 [==========================>...] - ETA: 1s1668/1782 [===========================>..] - ETA: 1s1674/1782 [===========================>..] - ETA: 1s1680/1782 [===========================>..] - ETA: 0s1686/1782 [===========================>..] - ETA: 0s1692/1782 [===========================>..] - ETA: 0s1698/1782 [===========================>..] - ETA: 0s1704/1782 [===========================>..] - ETA: 0s1710/1782 [===========================>..] - ETA: 0s1716/1782 [===========================>..] - ETA: 0s1722/1782 [===========================>..] - ETA: 0s1728/1782 [============================>.] - ETA: 0s1734/1782 [============================>.] - ETA: 0s1740/1782 [============================>.] - ETA: 0s1746/1782 [============================>.] - ETA: 0s1752/1782 [============================>.] - ETA: 0s1758/1782 [============================>.] - ETA: 0s1764/1782 [============================>.] - ETA: 0s1770/1782 [============================>.] - ETA: 0s1776/1782 [============================>.] - ETA: 0s1782/1782 [==============================] - ETA: 0s1782/1782 [==============================] - 20s 9ms/step
Performance of model 1

F1 score: 0.675
Accuracy: 0.676877
Confusion matrix: 

[[6530 1217  429  736  387  223]
 [ 571 8597  259  102    4    0]
 [ 622 1014 6423  408  519  533]
 [ 772   99  101 7532  464  517]
 [ 485    5   64  942 5052 2935]
 [ 394    4   74  985 3553 4448]]
Performance of model 1

F1 score: 0.815
Accuracy: 0.897614
Confusion matrix: 

[[ 6530  2992]
 [ 2844 44634]]
   1/1782 [..............................] - ETA: 36:16   7/1782 [..............................] - ETA: 17s    13/1782 [..............................] - ETA: 17s  19/1782 [..............................] - ETA: 17s  25/1782 [..............................] - ETA: 17s  31/1782 [..............................] - ETA: 17s  37/1782 [..............................] - ETA: 16s  43/1782 [..............................] - ETA: 16s  49/1782 [..............................] - ETA: 16s  55/1782 [..............................] - ETA: 16s  61/1782 [>.............................] - ETA: 16s  67/1782 [>.............................] - ETA: 16s  73/1782 [>.............................] - ETA: 16s  79/1782 [>.............................] - ETA: 16s  85/1782 [>.............................] - ETA: 16s  91/1782 [>.............................] - ETA: 16s  97/1782 [>.............................] - ETA: 16s 103/1782 [>.............................] - ETA: 16s 109/1782 [>.............................] - ETA: 15s 115/1782 [>.............................] - ETA: 15s 121/1782 [=>............................] - ETA: 15s 127/1782 [=>............................] - ETA: 15s 133/1782 [=>............................] - ETA: 15s 139/1782 [=>............................] - ETA: 15s 145/1782 [=>............................] - ETA: 15s 151/1782 [=>............................] - ETA: 15s 157/1782 [=>............................] - ETA: 15s 163/1782 [=>............................] - ETA: 15s 169/1782 [=>............................] - ETA: 15s 175/1782 [=>............................] - ETA: 15s 181/1782 [==>...........................] - ETA: 15s 187/1782 [==>...........................] - ETA: 15s 193/1782 [==>...........................] - ETA: 15s 199/1782 [==>...........................] - ETA: 15s 205/1782 [==>...........................] - ETA: 14s 211/1782 [==>...........................] - ETA: 14s 217/1782 [==>...........................] - ETA: 14s 223/1782 [==>...........................] - ETA: 14s 229/1782 [==>...........................] - ETA: 14s 235/1782 [==>...........................] - ETA: 14s 241/1782 [===>..........................] - ETA: 14s 247/1782 [===>..........................] - ETA: 14s 253/1782 [===>..........................] - ETA: 14s 259/1782 [===>..........................] - ETA: 14s 265/1782 [===>..........................] - ETA: 14s 271/1782 [===>..........................] - ETA: 14s 277/1782 [===>..........................] - ETA: 14s 283/1782 [===>..........................] - ETA: 14s 289/1782 [===>..........................] - ETA: 14s 295/1782 [===>..........................] - ETA: 14s 301/1782 [====>.........................] - ETA: 14s 307/1782 [====>.........................] - ETA: 14s 313/1782 [====>.........................] - ETA: 13s 319/1782 [====>.........................] - ETA: 13s 325/1782 [====>.........................] - ETA: 13s 331/1782 [====>.........................] - ETA: 13s 337/1782 [====>.........................] - ETA: 13s 343/1782 [====>.........................] - ETA: 13s 349/1782 [====>.........................] - ETA: 13s 355/1782 [====>.........................] - ETA: 13s 361/1782 [=====>........................] - ETA: 13s 367/1782 [=====>........................] - ETA: 13s 373/1782 [=====>........................] - ETA: 13s 379/1782 [=====>........................] - ETA: 13s 385/1782 [=====>........................] - ETA: 13s 391/1782 [=====>........................] - ETA: 13s 397/1782 [=====>........................] - ETA: 13s 403/1782 [=====>........................] - ETA: 13s 409/1782 [=====>........................] - ETA: 13s 415/1782 [=====>........................] - ETA: 12s 421/1782 [======>.......................] - ETA: 12s 427/1782 [======>.......................] - ETA: 12s 433/1782 [======>.......................] - ETA: 12s 439/1782 [======>.......................] - ETA: 12s 445/1782 [======>.......................] - ETA: 12s 451/1782 [======>.......................] - ETA: 12s 457/1782 [======>.......................] - ETA: 12s 463/1782 [======>.......................] - ETA: 12s 469/1782 [======>.......................] - ETA: 12s 475/1782 [======>.......................] - ETA: 12s 481/1782 [=======>......................] - ETA: 12s 487/1782 [=======>......................] - ETA: 12s 493/1782 [=======>......................] - ETA: 12s 499/1782 [=======>......................] - ETA: 12s 505/1782 [=======>......................] - ETA: 12s 511/1782 [=======>......................] - ETA: 12s 517/1782 [=======>......................] - ETA: 11s 523/1782 [=======>......................] - ETA: 11s 529/1782 [=======>......................] - ETA: 11s 535/1782 [========>.....................] - ETA: 11s 541/1782 [========>.....................] - ETA: 11s 547/1782 [========>.....................] - ETA: 11s 553/1782 [========>.....................] - ETA: 11s 559/1782 [========>.....................] - ETA: 11s 565/1782 [========>.....................] - ETA: 11s 571/1782 [========>.....................] - ETA: 11s 577/1782 [========>.....................] - ETA: 11s 583/1782 [========>.....................] - ETA: 11s 589/1782 [========>.....................] - ETA: 11s 595/1782 [=========>....................] - ETA: 11s 601/1782 [=========>....................] - ETA: 11s 607/1782 [=========>....................] - ETA: 11s 613/1782 [=========>....................] - ETA: 11s 619/1782 [=========>....................] - ETA: 11s 625/1782 [=========>....................] - ETA: 10s 631/1782 [=========>....................] - ETA: 10s 637/1782 [=========>....................] - ETA: 10s 643/1782 [=========>....................] - ETA: 10s 649/1782 [=========>....................] - ETA: 10s 655/1782 [==========>...................] - ETA: 10s 661/1782 [==========>...................] - ETA: 10s 667/1782 [==========>...................] - ETA: 10s 673/1782 [==========>...................] - ETA: 10s 679/1782 [==========>...................] - ETA: 10s 685/1782 [==========>...................] - ETA: 10s 691/1782 [==========>...................] - ETA: 10s 697/1782 [==========>...................] - ETA: 10s 703/1782 [==========>...................] - ETA: 10s 709/1782 [==========>...................] - ETA: 10s 715/1782 [===========>..................] - ETA: 10s 721/1782 [===========>..................] - ETA: 10s 727/1782 [===========>..................] - ETA: 9s  733/1782 [===========>..................] - ETA: 9s 739/1782 [===========>..................] - ETA: 9s 745/1782 [===========>..................] - ETA: 9s 751/1782 [===========>..................] - ETA: 9s 757/1782 [===========>..................] - ETA: 9s 763/1782 [===========>..................] - ETA: 9s 769/1782 [===========>..................] - ETA: 9s 775/1782 [============>.................] - ETA: 9s 781/1782 [============>.................] - ETA: 9s 787/1782 [============>.................] - ETA: 9s 793/1782 [============>.................] - ETA: 9s 799/1782 [============>.................] - ETA: 9s 805/1782 [============>.................] - ETA: 9s 811/1782 [============>.................] - ETA: 9s 817/1782 [============>.................] - ETA: 9s 823/1782 [============>.................] - ETA: 9s 829/1782 [============>.................] - ETA: 9s 835/1782 [=============>................] - ETA: 8s 841/1782 [=============>................] - ETA: 8s 847/1782 [=============>................] - ETA: 8s 853/1782 [=============>................] - ETA: 8s 859/1782 [=============>................] - ETA: 8s 865/1782 [=============>................] - ETA: 8s 871/1782 [=============>................] - ETA: 8s 877/1782 [=============>................] - ETA: 8s 883/1782 [=============>................] - ETA: 8s 889/1782 [=============>................] - ETA: 8s 895/1782 [==============>...............] - ETA: 8s 901/1782 [==============>...............] - ETA: 8s 907/1782 [==============>...............] - ETA: 8s 913/1782 [==============>...............] - ETA: 8s 919/1782 [==============>...............] - ETA: 8s 925/1782 [==============>...............] - ETA: 8s 931/1782 [==============>...............] - ETA: 8s 937/1782 [==============>...............] - ETA: 8s 943/1782 [==============>...............] - ETA: 7s 949/1782 [==============>...............] - ETA: 7s 955/1782 [===============>..............] - ETA: 7s 961/1782 [===============>..............] - ETA: 7s 967/1782 [===============>..............] - ETA: 7s 973/1782 [===============>..............] - ETA: 7s 979/1782 [===============>..............] - ETA: 7s 985/1782 [===============>..............] - ETA: 7s 991/1782 [===============>..............] - ETA: 7s 997/1782 [===============>..............] - ETA: 7s1003/1782 [===============>..............] - ETA: 7s1009/1782 [===============>..............] - ETA: 7s1015/1782 [================>.............] - ETA: 7s1021/1782 [================>.............] - ETA: 7s1027/1782 [================>.............] - ETA: 7s1033/1782 [================>.............] - ETA: 7s1039/1782 [================>.............] - ETA: 7s1045/1782 [================>.............] - ETA: 6s1051/1782 [================>.............] - ETA: 6s1057/1782 [================>.............] - ETA: 6s1063/1782 [================>.............] - ETA: 6s1069/1782 [================>.............] - ETA: 6s1075/1782 [=================>............] - ETA: 6s1081/1782 [=================>............] - ETA: 6s1087/1782 [=================>............] - ETA: 6s1093/1782 [=================>............] - ETA: 6s1099/1782 [=================>............] - ETA: 6s1105/1782 [=================>............] - ETA: 6s1111/1782 [=================>............] - ETA: 6s1117/1782 [=================>............] - ETA: 6s1123/1782 [=================>............] - ETA: 6s1129/1782 [==================>...........] - ETA: 6s1135/1782 [==================>...........] - ETA: 6s1141/1782 [==================>...........] - ETA: 6s1147/1782 [==================>...........] - ETA: 6s1153/1782 [==================>...........] - ETA: 5s1159/1782 [==================>...........] - ETA: 5s1165/1782 [==================>...........] - ETA: 5s1171/1782 [==================>...........] - ETA: 5s1177/1782 [==================>...........] - ETA: 5s1183/1782 [==================>...........] - ETA: 5s1189/1782 [===================>..........] - ETA: 5s1195/1782 [===================>..........] - ETA: 5s1201/1782 [===================>..........] - ETA: 5s1207/1782 [===================>..........] - ETA: 5s1213/1782 [===================>..........] - ETA: 5s1219/1782 [===================>..........] - ETA: 5s1225/1782 [===================>..........] - ETA: 5s1231/1782 [===================>..........] - ETA: 5s1237/1782 [===================>..........] - ETA: 5s1243/1782 [===================>..........] - ETA: 5s1249/1782 [====================>.........] - ETA: 5s1255/1782 [====================>.........] - ETA: 4s1261/1782 [====================>.........] - ETA: 4s1267/1782 [====================>.........] - ETA: 4s1273/1782 [====================>.........] - ETA: 4s1279/1782 [====================>.........] - ETA: 4s1285/1782 [====================>.........] - ETA: 4s1291/1782 [====================>.........] - ETA: 4s1297/1782 [====================>.........] - ETA: 4s1303/1782 [====================>.........] - ETA: 4s1309/1782 [=====================>........] - ETA: 4s1315/1782 [=====================>........] - ETA: 4s1321/1782 [=====================>........] - ETA: 4s1327/1782 [=====================>........] - ETA: 4s1333/1782 [=====================>........] - ETA: 4s1339/1782 [=====================>........] - ETA: 4s1345/1782 [=====================>........] - ETA: 4s1351/1782 [=====================>........] - ETA: 4s1357/1782 [=====================>........] - ETA: 4s1363/1782 [=====================>........] - ETA: 3s1369/1782 [======================>.......] - ETA: 3s1375/1782 [======================>.......] - ETA: 3s1381/1782 [======================>.......] - ETA: 3s1387/1782 [======================>.......] - ETA: 3s1393/1782 [======================>.......] - ETA: 3s1399/1782 [======================>.......] - ETA: 3s1405/1782 [======================>.......] - ETA: 3s1411/1782 [======================>.......] - ETA: 3s1417/1782 [======================>.......] - ETA: 3s1423/1782 [======================>.......] - ETA: 3s1429/1782 [=======================>......] - ETA: 3s1435/1782 [=======================>......] - ETA: 3s1441/1782 [=======================>......] - ETA: 3s1447/1782 [=======================>......] - ETA: 3s1453/1782 [=======================>......] - ETA: 3s1459/1782 [=======================>......] - ETA: 3s1465/1782 [=======================>......] - ETA: 2s1471/1782 [=======================>......] - ETA: 2s1477/1782 [=======================>......] - ETA: 2s1483/1782 [=======================>......] - ETA: 2s1489/1782 [========================>.....] - ETA: 2s1495/1782 [========================>.....] - ETA: 2s1501/1782 [========================>.....] - ETA: 2s1507/1782 [========================>.....] - ETA: 2s1513/1782 [========================>.....] - ETA: 2s1519/1782 [========================>.....] - ETA: 2s1525/1782 [========================>.....] - ETA: 2s1531/1782 [========================>.....] - ETA: 2s1537/1782 [========================>.....] - ETA: 2s1543/1782 [========================>.....] - ETA: 2s1549/1782 [=========================>....] - ETA: 2s1555/1782 [=========================>....] - ETA: 2s1561/1782 [=========================>....] - ETA: 2s1567/1782 [=========================>....] - ETA: 2s1573/1782 [=========================>....] - ETA: 1s1579/1782 [=========================>....] - ETA: 1s1585/1782 [=========================>....] - ETA: 1s1591/1782 [=========================>....] - ETA: 1s1597/1782 [=========================>....] - ETA: 1s1603/1782 [=========================>....] - ETA: 1s1609/1782 [==========================>...] - ETA: 1s1615/1782 [==========================>...] - ETA: 1s1621/1782 [==========================>...] - ETA: 1s1627/1782 [==========================>...] - ETA: 1s1633/1782 [==========================>...] - ETA: 1s1639/1782 [==========================>...] - ETA: 1s1645/1782 [==========================>...] - ETA: 1s1651/1782 [==========================>...] - ETA: 1s1657/1782 [==========================>...] - ETA: 1s1663/1782 [==========================>...] - ETA: 1s1669/1782 [===========================>..] - ETA: 1s1675/1782 [===========================>..] - ETA: 1s1681/1782 [===========================>..] - ETA: 0s1687/1782 [===========================>..] - ETA: 0s1693/1782 [===========================>..] - ETA: 0s1699/1782 [===========================>..] - ETA: 0s1705/1782 [===========================>..] - ETA: 0s1711/1782 [===========================>..] - ETA: 0s1717/1782 [===========================>..] - ETA: 0s1723/1782 [============================>.] - ETA: 0s1729/1782 [============================>.] - ETA: 0s1735/1782 [============================>.] - ETA: 0s1741/1782 [============================>.] - ETA: 0s1747/1782 [============================>.] - ETA: 0s1753/1782 [============================>.] - ETA: 0s1759/1782 [============================>.] - ETA: 0s1765/1782 [============================>.] - ETA: 0s1771/1782 [============================>.] - ETA: 0s1777/1782 [============================>.] - ETA: 0s1782/1782 [==============================] - 18s 9ms/step
Performance of model 2

F1 score: 0.857
Accuracy: 0.856772
Confusion matrix: 

[[9136  256   16   28   37   49]
 [ 113 9404   16    0    0    0]
 [  53  622 8295   33  161  355]
 [  85    0    5 9154  120  121]
 [  90    0   18  225 6624 2526]
 [  96    0   29  247 2863 6223]]
Performance of model 2

F1 score: 0.974
Accuracy: 0.985561
Confusion matrix: 

[[ 9136   386]
 [  437 47041]]
Script took 188.6 seconds
-----
 Make Sup Fig 2 - example training simulations 
-----
-----
 Make Sup Fig 3 - example model test simulations 
-----
-----
 Test DL classifier and EWS on Fox model 
-----
2023-03-10 18:06:34.595562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:06:36.187717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:06:36.188486: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:06:36.188582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 18:06:41.021058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:06:41.823036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 18:07:19.359308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 18:07:19.730977: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
Running for 2500 sims
TF models loaded
Simulate forced trajectories and compute EWS
Complete for rof=0.2
Complete for rof=0.25
Complete for rof=0.3333333333333333
Complete for rof=0.5
Complete for rof=1.0
Script took 1590.62 seconds
Compute ROC curves
Exported bifurcation count data to output/df_fav_bif.csv
Exported ROC data to output/df_roc.csv
-----
 Test DL classifier and EWS on Westerhoff model 
-----
2023-03-10 18:33:13.423602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:33:14.987707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:33:14.988482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:33:14.988553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 18:33:19.843641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:33:20.649163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 18:33:58.846238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 18:33:59.216644: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
Running for 2500 sims
TF models loaded
Simulate forced trajectories and compute EWS
Complete for rof=0.02
Complete for rof=0.025
Complete for rof=0.03333333333333333
Complete for rof=0.05
Complete for rof=0.1
Script took 1568.57 seconds
Compute ROC curves
Exported bifurcation count data to output/df_fav_bif.csv
Exported ROC data to output/df_roc.csv
-----
 Test DL classifier and EWS on Ricker model 
-----
2023-03-10 18:59:30.150535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:59:31.723407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:59:31.724203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 18:59:31.724293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 18:59:36.563660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 18:59:37.372181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 19:00:15.789806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 19:00:16.156647: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
Running for 2500 sims
TF models loaded
Simulate forced trajectories and compute EWS
Complete for rof=0.004719999999999999
Complete for rof=0.0059
Complete for rof=0.007866666666666666
Complete for rof=0.0118
Complete for rof=0.0236
Script took 1582.75 seconds
Compute ROC curves
Exported bifurcation count data to output/df_fav_bif.csv
Exported ROC data to output/df_roc.csv
-----
 Test DL classifier and EWS on Kot model 
-----
2023-03-10 19:26:01.395888: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 19:26:02.966615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 19:26:02.967412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 19:26:02.967489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 19:26:07.758198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 19:26:08.574239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 19:26:46.567454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 19:26:46.943948: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
Running for 2500 sims
TF models loaded
Simulate forced trajectories and compute EWS
Complete for rof=0.001
Complete for rof=0.00125
Complete for rof=0.0016666666666666668
Complete for rof=0.0025
Complete for rof=0.005
Script took 1590.94 seconds
Compute ROC curves
Exported bifurcation count data to output/df_fav_bif.csv
Exported ROC data to output/df_roc.csv
-----
 Test DL classifier and EWS on Lorenz model 
-----
2023-03-10 19:52:40.496761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 19:52:42.083312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 19:52:42.084146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 19:52:42.084236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 19:52:46.930058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 19:52:47.729112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 19:53:26.345866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 19:53:26.715434: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
Running for 2500 sims
TF models loaded
Simulate forced trajectories and compute EWS
Complete for rof=0.002
Complete for rof=0.0025
Complete for rof=0.0033333333333333335
Complete for rof=0.005
Complete for rof=0.01
Script took 1597.06 seconds
Compute ROC curves
Exported bifurcation count data to output/df_fav_bif.csv
Exported ROC data to output/df_roc.csv
-----
 Make Figure 2 - EWS and DL predictions for sample model simulations 
-----
2023-03-10 20:19:26.198684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:19:27.664179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:19:27.664751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:19:27.664815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 20:19:32.756556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:19:33.562413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 20:20:11.204173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 20:20:11.578053: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
TF models loaded
EWS computed for Fox model
EWS computed for Westerhoff model
EWS computed for Ricker model
EWS computed for Kot model
EWS computed for Lorenz model
Script took 99.08s
2023-03-10 20:21:07.835456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:21:09.229882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:21:09.230405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:21:09.230467: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
-----
 Make Sup Fig 4 - AUC scores across rof and sigma 
-----
For the Fox model, the DL performs best in 84.0% of cases
For the Westerhoff model, the DL performs best in 100.0% of cases
For the Ricker model, the DL performs best in 100.0% of cases
For the predator-prey model, the DL performs best in 80.0% of cases
For the Lorenz model, the DL performs best in 100.0% of cases
-----
 Make Sup Fig 5 - DL favourite bifurcation prop. correct 
-----
-----
 Find transition times in chick heart data 
-----
Transition for tsid = 1 at beat 440
Transition for tsid = 2 at beat 410
Transition for tsid = 3 at beat 303
Transition for tsid = 4 at beat 338
Transition for tsid = 5 at beat 345
Transition for tsid = 6 at beat 249
Transition for tsid = 7 at beat 151
Transition for tsid = 8 at beat 222
Transition for tsid = 9 at beat 96
Transition for tsid = 10 at beat 297
Transition for tsid = 11 at beat 313
Transition for tsid = 12 at beat 198
Transition for tsid = 13 at beat 231
Transition for tsid = 14 at beat 299
Transition for tsid = 15 at beat 200
Transition for tsid = 16 at beat 301
Transition for tsid = 17 at beat 234
Transition for tsid = 18 at beat 340
Transition for tsid = 19 at beat 198
Transition for tsid = 20 at beat 262
Transition for tsid = 21 at beat 148
Transition for tsid = 22 at beat 187
Transition for tsid = 23 at beat 324
-----
 Compute EWS in chick heart data 
-----
2023-03-10 20:21:51.501408: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:21:53.041967: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:21:53.042546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:21:53.042611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 20:21:57.822691: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:21:58.632276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 20:22:36.418670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 20:22:36.809165: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
Using time increment of 5 for DL predictions
TF models loaded
Complete for tsid=1
Complete for tsid=2
Complete for tsid=3
Complete for tsid=4
Complete for tsid=5
Complete for tsid=6
Complete for tsid=7
Complete for tsid=8
Complete for tsid=9
Complete for tsid=10
Complete for tsid=11
Complete for tsid=12
Complete for tsid=13
Complete for tsid=14
Complete for tsid=15
Complete for tsid=16
Complete for tsid=17
Complete for tsid=18
Complete for tsid=19
Complete for tsid=20
Complete for tsid=21
Complete for tsid=22
Complete for tsid=23
Complete for tsid=1
Complete for tsid=2
Complete for tsid=3
Complete for tsid=4
Complete for tsid=5
Complete for tsid=6
Complete for tsid=7
Complete for tsid=8
Complete for tsid=9
Complete for tsid=10
Complete for tsid=11
Complete for tsid=12
Complete for tsid=13
Complete for tsid=14
Complete for tsid=15
Complete for tsid=16
Complete for tsid=17
Complete for tsid=18
Complete for tsid=19
Complete for tsid=20
Complete for tsid=21
Complete for tsid=22
Complete for tsid=23
Ran in 543.46s
-----
 Test EWS and DL in chick heart data 
-----
2023-03-10 20:30:57.880326: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:30:59.435795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:30:59.436563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:30:59.436657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-03-10 20:31:04.251144: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:31:05.056729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11306 MB memory:  -> device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0
2023-03-10 20:31:43.299122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200
2023-03-10 20:31:43.677649: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.
TF models loaded
Complete for pd tsid=1
Complete for pd tsid=2
Complete for pd tsid=3
Complete for pd tsid=4
Complete for pd tsid=5
Complete for pd tsid=6
Complete for pd tsid=7
Complete for pd tsid=8
Complete for pd tsid=9
Complete for pd tsid=10
Complete for pd tsid=11
Complete for pd tsid=12
Complete for pd tsid=13
Complete for pd tsid=14
Complete for pd tsid=15
Complete for pd tsid=16
Complete for pd tsid=17
Complete for pd tsid=18
Complete for pd tsid=19
Complete for pd tsid=20
Complete for pd tsid=21
Complete for pd tsid=22
Complete for pd tsid=23
Simulate null trajectories and compute EWS
Complete for null tsid=1
Complete for null tsid=2
Complete for null tsid=3
Complete for null tsid=4
Complete for null tsid=5
Complete for null tsid=6
Complete for null tsid=7
Complete for null tsid=8
Complete for null tsid=9
Complete for null tsid=10
Complete for null tsid=11
Complete for null tsid=12
Complete for null tsid=13
Complete for null tsid=14
Complete for null tsid=15
Complete for null tsid=16
Complete for null tsid=17
Complete for null tsid=18
Complete for null tsid=19
Complete for null tsid=20
Complete for null tsid=21
Complete for null tsid=22
Complete for null tsid=23
Ran in 143.99s
2023-03-10 20:33:24.356834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-10 20:33:25.882861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:33:25.883842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-10 20:33:25.883912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Compute ROC curves
Exported bifurcation count data to output/df_fav_bif.csv
Exported ROC data to output/df_roc.csv
-----
 Make figure 3 - sample EWS and DL preds in chick heart data 
-----
Ran in 6.88s
-----
 Make Fig S6 S7 - EWS in chick heart period-doubling 
-----
Exported image 1
Exported image 2
Exported image 3
Exported image 4
Exported image 5
Exported image 6
Exported image 7
Exported image 8
Exported image 9
Exported image 10
Exported image 11
Exported image 12
Exported image 13
Exported image 14
Exported image 15
Exported image 16
Exported image 17
Exported image 18
Exported image 19
Exported image 20
Exported image 21
Exported image 22
Exported image 23
Ran in 10.88s
-----
 Make Fig S8 S9 - EWS in chick heart null 
-----
Exported image 1
Exported image 2
Exported image 3
Exported image 4
Exported image 5
Exported image 6
Exported image 7
Exported image 8
Exported image 9
Exported image 10
Exported image 11
Exported image 12
Exported image 13
Exported image 14
Exported image 15
Exported image 16
Exported image 17
Exported image 18
Exported image 19
Exported image 20
Exported image 21
Exported image 22
Exported image 23
Ran in 10.88s
-----
 Make Figure 4 - ROC curves 
-----
findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.
Ran in 14.00s
